<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>enrgdaq.daq.base API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>enrgdaq.daq.base</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="enrgdaq.daq.base.DAQJob"><code class="flex name class">
<span>class <span class="ident">DAQJob</span></span>
<span>(</span><span>config: <a title="enrgdaq.daq.models.DAQJobConfig" href="models.html#enrgdaq.daq.models.DAQJobConfig">DAQJobConfig</a>,<br>supervisor_info: <a title="enrgdaq.models.SupervisorInfo" href="../models.html#enrgdaq.models.SupervisorInfo">SupervisorInfo</a> | None = None,<br>instance_id: int | None = None,<br>message_in: Any = None,<br>message_out: Any = None,<br>raw_config: str | None = None,<br>zmq_xpub_url: str | None = None,<br>zmq_xsub_url: str | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJob:
    &#34;&#34;&#34;
    DAQJob is a base class for data acquisition jobs. It handles the configuration,
    message queues, and provides methods for consuming and handling messages.
    Attributes:
        allowed_message_in_types (list[type[DAQJobMessage]]): List of allowed message types for input.
        config_type (Any): Type of the configuration.
        config (Any): Configuration object.
        message_in (Queue[DAQJobMessage]): Queue for incoming messages.
        message_out (Queue[DAQJobMessage]): Queue for outgoing messages.
        instance_id (int): Unique instance identifier.
        unique_id (str): Unique identifier for the job.
        restart_offset (timedelta): Offset for restarting the job.
        info (DAQJobInfo): Information about the job.
        _has_been_freed (bool): Flag indicating if the job has been freed.
        _logger (logging.Logger): Logger instance for the job.
        multiprocessing_method (str): The multiprocessing method to use (&#39;fork&#39; or &#39;spawn&#39;).
    &#34;&#34;&#34;

    allowed_message_in_types = []

    topics_to_subscribe: list[str] = []
    config_type: type[DAQJobConfig]  # pyright: ignore[reportUninitializedInstanceVariable]
    config: DAQJobConfig
    message_in: Any
    message_out: Any
    instance_id: int
    unique_id: str
    restart_offset: timedelta  # pyright: ignore[reportUninitializedInstanceVariable]
    info: &#34;DAQJobInfo&#34;
    _has_been_freed: bool
    _logger: logging.Logger
    multiprocessing_method: str = &#34;default&#34;  # Can be &#39;fork&#39;, &#39;spawn&#39;, or &#39;default&#39;
    watchdog_timeout_seconds: float = 0  # Watchdog timeout in seconds, 0 = disabled
    watchdog_force_exit: bool = (
        False  # If True, force exit on timeout (for blocking calls)
    )
    _watchdog: Watchdog
    _supervisor_info: SupervisorInfo | None
    _consume_thread: threading.Thread | None = None

    def __init__(
        self,
        config: DAQJobConfig,
        supervisor_info: SupervisorInfo | None = None,
        instance_id: int | None = None,
        message_in: Any = None,
        message_out: Any = None,
        raw_config: str | None = None,
        zmq_xpub_url: str | None = None,
        zmq_xsub_url: str | None = None,
    ):
        self.instance_id = instance_id or 0
        self._logger = logging.getLogger(f&#34;{type(self).__name__}({self.instance_id})&#34;)

        # TODO: In some tests config is a dict, so we need to check for this
        if isinstance(config, DAQJobConfig):  # pyright: ignore[reportUnnecessaryIsInstance]
            self._logger.setLevel(config.verbosity.to_logging_level())

        self.config = config
        self.message_in = message_in or _create_queue()
        self.message_out = message_out or _create_queue()

        self._has_been_freed = False
        self.unique_id = getattr(config, &#34;daq_job_unique_id&#34;, None) or str(uuid.uuid4())

        self._supervisor_info = supervisor_info

        self.info = self._create_info(raw_config)
        self._logger.debug(f&#34;DAQ job {self.info.unique_id} created&#34;)

        self._watchdog = Watchdog(
            timeout_seconds=self.watchdog_timeout_seconds,
            force_exit=self.watchdog_force_exit,
            logger=self._logger,
        )

        self._latency_samples: list[float] = []
        self._processed_count = 0
        self._processed_bytes = 0
        self._sent_count = 0
        self._sent_bytes = 0
        self._last_stats_report_time = datetime.now()

        # Trace collection
        self._trace_events: list[DAQJobMessageTraceEvent] = []
        self._last_trace_report_time = datetime.now()

        self.topics_to_subscribe.extend(
            [
                Topic.supervisor_broadcast(self.supervisor_id),
                Topic.daq_job_direct(type(self).__name__, self.unique_id),
            ]
        )
        self.info.subscribed_topics = self.topics_to_subscribe

        self._zmq_xpub_url = zmq_xpub_url
        self._zmq_xsub_url = zmq_xsub_url

        self._consume_thread = threading.Thread(
            target=self._consume_thread_func, daemon=True
        )
        self._publish_thread = threading.Thread(
            target=self._publish_thread_func, daemon=True
        )
        self._publish_buffer = queue.Queue()
        self._consume_thread.start()
        self._publish_thread.start()

    def get_job_started_message(self):
        return self._prepare_message(DAQJobMessageJobStarted())

    def _consume_thread_func(self):
        assert self._zmq_xpub_url is not None

        # Connect to zmq xpub
        self.zmq_context = zmq.Context()
        zmq_xpub = self.zmq_context.socket(zmq.SUB)
        zmq_xpub.setsockopt_string(zmq.IDENTITY, self.unique_id)
        zmq_xpub.connect(self._zmq_xpub_url)
        # Subscribe to topics
        for topic in self.topics_to_subscribe:
            zmq_xpub.subscribe(topic)

        self._logger.debug(
            f&#34;Subscribed to topics: {&#39;, &#39;.join(self.topics_to_subscribe)}&#34;
        )

        # Start receiving messages
        while not self._has_been_freed:
            try:
                parts = zmq_xpub.recv_multipart()
                topic = parts[0]
                header = parts[1]
                buffers = parts[2:]

                message_len = len(header) + sum(len(b) for b in buffers)
                recv_message = pickle.loads(header, buffers=buffers)
                if isinstance(recv_message, DAQJobMessageSHM) or isinstance(
                    recv_message, DAQJobMessageStoreSHM
                ):
                    message_len += recv_message.shm.shm_size
                elif isinstance(recv_message, DAQJobMessageStorePyArrow):
                    if recv_message.handle is not None:
                        message_len += recv_message.handle.data_size

                recv_message = self._unwrap_message(recv_message)
                self._logger.debug(
                    f&#34;Received message of size {message_len} bytes &#39;{type(recv_message).__name__}&#39; on topic &#39;{topic.decode()}&#39;&#34;
                )
                recv_message.is_remote = True
                self.handle_message(recv_message)
                self._processed_bytes += message_len

                # Record received trace event (skip internal messages)
                if not isinstance(recv_message, InternalDAQJobMessage):
                    self._trace_events.append(
                        DAQJobMessageTraceEvent(
                            message_id=recv_message.id or &#34;unknown&#34;,
                            message_type=type(recv_message).__name__,
                            event_type=&#34;received&#34;,
                            topics=list(recv_message.topics),
                            timestamp=datetime.now(),
                            size_bytes=message_len,
                            source_job=type(self).__name__,
                            source_supervisor=self.supervisor_id,
                        )
                    )

                self.report_stats()
                self.report_traces()
            except zmq.ContextTerminated:
                break
            except Exception as e:
                self._logger.error(
                    f&#34;Error while unpacking message sent in {topic}: {e}&#34;,
                    exc_info=True,
                )

    def _publish_thread_func(self):
        assert self._zmq_xsub_url is not None
        # Connect to zmq xsub
        self.zmq_context = zmq.Context()
        zmq_xsub = self.zmq_context.socket(zmq.PUB)
        zmq_xsub.setsockopt_string(zmq.IDENTITY, self.unique_id)
        zmq_xsub.connect(self._zmq_xsub_url)

        buffer = []
        while not self._has_been_freed:
            message: DAQJobMessage = self._publish_buffer.get()
            if message is None:
                break
            send_message(zmq_xsub, message, buffer)
            self.report_stats()

    def _unwrap_message(self, message: DAQJobMessage) -&gt; DAQJobMessage:
        if isinstance(message, DAQJobMessageSHM) or isinstance(
            message, DAQJobMessageStoreSHM
        ):
            res = message.shm.load()
            message.shm.cleanup()
            return res
        return message

    def handle_message(self, message: &#34;DAQJobMessage&#34;) -&gt; bool:
        &#34;&#34;&#34;
        Handles a message received from the message queue.

        Args:
            message (DAQJobMessage): The message to handle.

        Returns:
            bool: True if the message was handled, False otherwise.

        Raises:
            DAQJobStopError: If the message is a DAQJobMessageStop.
            Exception: If the message is not accepted by the job.
        &#34;&#34;&#34;

        if isinstance(message, DAQJobMessageStop):
            self.free()
            raise DAQJobStopError(message.reason)
        # check if the message is accepted
        is_message_type_accepted = False
        for accepted_message_type in self.allowed_message_in_types:
            if isinstance(message, accepted_message_type):
                is_message_type_accepted = True
        if not is_message_type_accepted:
            raise Exception(
                f&#34;Message type &#39;{type(message)}&#39; is not accepted by &#39;{type(self).__name__}&#39;&#34;
            )

        self._processed_count += 1

        if message.timestamp and isinstance(message, DAQJobMessageStore):
            latency = (datetime.now() - message.timestamp).total_seconds() * 1000.0
            self._latency_samples.append(latency)

            # Keep only last 1000 samples
            if len(self._latency_samples) &gt; 1000:
                self._latency_samples.pop(0)

        return True

    def start(self):
        raise NotImplementedError

    def _create_info(self, raw_config: Optional[str] = None) -&gt; &#34;DAQJobInfo&#34;:
        &#34;&#34;&#34;
        Creates a DAQJobInfo object for the job.

        Returns:
            DAQJobInfo: The created DAQJobInfo object.
        &#34;&#34;&#34;

        return DAQJobInfo(
            daq_job_type=self.config.daq_job_type
            if isinstance(self.config, DAQJobConfig)
            else self.config[&#34;daq_job_type&#34;],
            unique_id=self.unique_id,
            instance_id=self.instance_id,
            supervisor_info=getattr(self, &#34;_supervisor_info&#34;, None),
            config=raw_config or &#34;# No config&#34;,
            subscribed_topics=self.topics_to_subscribe,
        )

    def _prepare_message(
        self, message: DAQJobMessage, use_shm=False, modify_message_metadata=True
    ):
        &#34;&#34;&#34;
        Prepares a message for sending.

        Args:
            message (DAQJobMessage): The message to put in the queue.
        &#34;&#34;&#34;

        if modify_message_metadata:
            message.daq_job_info = self.info

        omit_debug_message = not isinstance(
            message, DAQJobMessageStatsReport
        ) and not isinstance(message, InternalDAQJobMessage)
        if self.config.verbosity == LogVerbosity.DEBUG and omit_debug_message:
            self._logger.debug(f&#34;Message out: {_format_message_for_log(message)}&#34;)

        if (
            use_shm
            and self.config.use_shm_when_possible
            # Should be not store message, or if it is, it should target local supervisor
            and (
                not isinstance(message, DAQJobMessageStore)
                or message.target_local_supervisor
            )
            # Should not be Windows
            and sys.platform != &#34;win32&#34;
        ):
            original_message = message

            # Use zero-copy ring buffer for PyArrow messages
            if (
                isinstance(message, DAQJobMessageStorePyArrow)
                and message.table is not None
            ):
                handle, success = try_zero_copy_pyarrow(
                    message.table,
                    message.store_config,
                    message.tag,
                )
                if success and handle is not None:
                    message = DAQJobMessageStorePyArrow(
                        store_config=message.store_config,
                        tag=message.tag,
                        table=None,
                        handle=handle,
                    )
                    message.daq_job_info = self.info
                    message.topics = original_message.topics
                else:
                    # Fall back to regular pickle-based SHM
                    pass
            else:
                # For non-PyArrow messages, use the existing pickle-based approach
                pass

            # Standard SHM path for non-PyArrow or fallback
            if not (
                isinstance(message, DAQJobMessageStorePyArrow)
                and message.handle is not None
            ):
                # Pickle message
                message_bytes = pickle.dumps(message)
                # Create shared memory object
                shm = SharedMemory(create=True, size=len(message_bytes))
                assert shm.buf is not None, &#34;Shared memory buffer is None&#34;
                # Write message to shared memory
                shm.buf[: len(message_bytes)] = message_bytes
                shm.close()
                shm_handle = SHMHandle(shm_name=shm.name, shm_size=shm.size)
                if isinstance(original_message, DAQJobMessageStore):
                    message = DAQJobMessageStoreSHM(
                        store_config=getattr(original_message, &#34;store_config&#34;),
                        tag=getattr(original_message, &#34;tag&#34;, None),
                        shm=shm_handle,
                    )
                else:
                    message = DAQJobMessageSHM(
                        shm=shm_handle,
                    )
                message.daq_job_info = self.info
                message.topics = original_message.topics

        return message

    def _put_message_out(
        self, message: DAQJobMessage, use_shm=False, modify_message_metadata=True
    ):
        &#34;&#34;&#34;
        Sends the message to its described topics.

        Args:
            message (DAQJobMessage): The message to put in the queue.
        &#34;&#34;&#34;
        message = self._prepare_message(message, use_shm, modify_message_metadata)
        self._publish_buffer.put(message)
        self._sent_count += 1

        # Record sent trace event (skip internal messages to avoid loops)
        if not isinstance(message, InternalDAQJobMessage):
            # Estimate size using pickle (approximation)
            try:
                sent_size = len(pickle.dumps(message))
            except Exception:
                sent_size = 0
            self._trace_events.append(
                DAQJobMessageTraceEvent(
                    message_id=message.id or &#34;unknown&#34;,
                    message_type=type(message).__name__,
                    event_type=&#34;sent&#34;,
                    topics=list(message.topics),
                    timestamp=datetime.now(),
                    size_bytes=sent_size,
                    source_job=type(self).__name__,
                    source_supervisor=self.supervisor_id,
                )
            )

    def get_latency_stats(self) -&gt; Any:
        if not self._latency_samples:
            return DAQJobLatencyStats()

        samples = sorted(self._latency_samples)
        count = len(samples)
        return DAQJobLatencyStats(
            count=self._processed_count,
            min_ms=samples[0],
            max_ms=samples[-1],
            avg_ms=sum(samples) / count,
            p95_ms=samples[int(count * 0.95)],
            p99_ms=samples[int(count * 0.99)],
        )

    def report_stats(self, force: bool = False):
        if (
            not force
            and (datetime.now() - self._last_stats_report_time).total_seconds()
            &lt; DAQ_JOB_STATS_REPORT_INTERVAL_SECONDS
        ):
            return

        self._last_stats_report_time = datetime.now()
        report = DAQJobMessageStatsReport(
            processed_count=self._processed_count,
            processed_bytes=self._processed_bytes,
            sent_count=self._sent_count,
            sent_bytes=self._sent_bytes,
            latency=self.get_latency_stats(),
        )
        self._put_message_out(report)
        self._latency_samples = []  # RESET after report to get interval stats

    def report_traces(self, force: bool = False):
        if (
            not force
            and (datetime.now() - self._last_trace_report_time).total_seconds()
            &lt; DAQ_JOB_TRACE_REPORT_INTERVAL_SECONDS
        ):
            return

        if not self._trace_events:
            return

        self._last_trace_report_time = datetime.now()
        report = DAQJobMessageTraceReport(events=self._trace_events.copy())
        self._put_message_out(report)
        self._trace_events.clear()

    def __del__(self):
        self._logger.info(&#34;DAQ job is being deleted&#34;)
        self._has_been_freed = True

    @property
    def supervisor_id(self):
        if self.info.supervisor_info is None:
            return &#34;unknown&#34;
        return self.info.supervisor_info.supervisor_id

    def free(self):
        if self._has_been_freed:
            return
        self._has_been_freed = True
        self.__del__()</code></pre>
</details>
<div class="desc"><p>DAQJob is a base class for data acquisition jobs. It handles the configuration,
message queues, and provides methods for consuming and handling messages.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>allowed_message_in_types</code></strong> :&ensp;<code>list[type[DAQJobMessage]]</code></dt>
<dd>List of allowed message types for input.</dd>
<dt><strong><code>config_type</code></strong> :&ensp;<code>Any</code></dt>
<dd>Type of the configuration.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Any</code></dt>
<dd>Configuration object.</dd>
<dt><strong><code>message_in</code></strong> :&ensp;<code>Queue[DAQJobMessage]</code></dt>
<dd>Queue for incoming messages.</dd>
<dt><strong><code>message_out</code></strong> :&ensp;<code>Queue[DAQJobMessage]</code></dt>
<dd>Queue for outgoing messages.</dd>
<dt><strong><code>instance_id</code></strong> :&ensp;<code>int</code></dt>
<dd>Unique instance identifier.</dd>
<dt><strong><code>unique_id</code></strong> :&ensp;<code>str</code></dt>
<dd>Unique identifier for the job.</dd>
<dt><strong><code>restart_offset</code></strong> :&ensp;<code>timedelta</code></dt>
<dd>Offset for restarting the job.</dd>
<dt><strong><code>info</code></strong> :&ensp;<code>DAQJobInfo</code></dt>
<dd>Information about the job.</dd>
<dt><strong><code>_has_been_freed</code></strong> :&ensp;<code>bool</code></dt>
<dd>Flag indicating if the job has been freed.</dd>
<dt><strong><code>_logger</code></strong> :&ensp;<code>logging.Logger</code></dt>
<dd>Logger instance for the job.</dd>
<dt><strong><code>multiprocessing_method</code></strong> :&ensp;<code>str</code></dt>
<dd>The multiprocessing method to use ('fork' or 'spawn').</dd>
</dl></div>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="enrgdaq.daq.alert.base.DAQJobAlert" href="alert/base.html#enrgdaq.daq.alert.base.DAQJobAlert">DAQJobAlert</a></li>
<li><a title="enrgdaq.daq.jobs.benchmark.DAQJobBenchmark" href="jobs/benchmark.html#enrgdaq.daq.jobs.benchmark.DAQJobBenchmark">DAQJobBenchmark</a></li>
<li><a title="enrgdaq.daq.jobs.caen.digitizer.DAQJobCAENDigitizer" href="jobs/caen/digitizer.html#enrgdaq.daq.jobs.caen.digitizer.DAQJobCAENDigitizer">DAQJobCAENDigitizer</a></li>
<li><a title="enrgdaq.daq.jobs.caen.hv.DAQJobCAENHV" href="jobs/caen/hv.html#enrgdaq.daq.jobs.caen.hv.DAQJobCAENHV">DAQJobCAENHV</a></li>
<li><a title="enrgdaq.daq.jobs.caen.toolbox.DAQJobCAENToolbox" href="jobs/caen/toolbox.html#enrgdaq.daq.jobs.caen.toolbox.DAQJobCAENToolbox">DAQJobCAENToolbox</a></li>
<li><a title="enrgdaq.daq.jobs.camera.DAQJobCamera" href="jobs/camera.html#enrgdaq.daq.jobs.camera.DAQJobCamera">DAQJobCamera</a></li>
<li><a title="enrgdaq.daq.jobs.handle_alerts.DAQJobHandleAlerts" href="jobs/handle_alerts.html#enrgdaq.daq.jobs.handle_alerts.DAQJobHandleAlerts">DAQJobHandleAlerts</a></li>
<li><a title="enrgdaq.daq.jobs.handle_stats.DAQJobHandleStats" href="jobs/handle_stats.html#enrgdaq.daq.jobs.handle_stats.DAQJobHandleStats">DAQJobHandleStats</a></li>
<li><a title="enrgdaq.daq.jobs.handle_traces.DAQJobHandleTraces" href="jobs/handle_traces.html#enrgdaq.daq.jobs.handle_traces.DAQJobHandleTraces">DAQJobHandleTraces</a></li>
<li><a title="enrgdaq.daq.jobs.healthcheck.DAQJobHealthcheck" href="jobs/healthcheck.html#enrgdaq.daq.jobs.healthcheck.DAQJobHealthcheck">DAQJobHealthcheck</a></li>
<li><a title="enrgdaq.daq.jobs.pc_metrics.DAQJobPCMetrics" href="jobs/pc_metrics.html#enrgdaq.daq.jobs.pc_metrics.DAQJobPCMetrics">DAQJobPCMetrics</a></li>
<li><a title="enrgdaq.daq.jobs.sensor.xiaomi_mijia.DAQJobXiaomiMijia" href="jobs/sensor/xiaomi_mijia.html#enrgdaq.daq.jobs.sensor.xiaomi_mijia.DAQJobXiaomiMijia">DAQJobXiaomiMijia</a></li>
<li><a title="enrgdaq.daq.jobs.serve_http.DAQJobServeHTTP" href="jobs/serve_http.html#enrgdaq.daq.jobs.serve_http.DAQJobServeHTTP">DAQJobServeHTTP</a></li>
<li><a title="enrgdaq.daq.jobs.test_job.DAQJobTest" href="jobs/test_job.html#enrgdaq.daq.jobs.test_job.DAQJobTest">DAQJobTest</a></li>
<li><a title="enrgdaq.daq.store.base.DAQJobStore" href="store/base.html#enrgdaq.daq.store.base.DAQJobStore">DAQJobStore</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="enrgdaq.daq.base.DAQJob.allowed_message_in_types"><code class="name">var <span class="ident">allowed_message_in_types</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.config"><code class="name">var <span class="ident">config</span> : <a title="enrgdaq.daq.models.DAQJobConfig" href="models.html#enrgdaq.daq.models.DAQJobConfig">DAQJobConfig</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.config_type"><code class="name">var <span class="ident">config_type</span> : type[<a title="enrgdaq.daq.models.DAQJobConfig" href="models.html#enrgdaq.daq.models.DAQJobConfig">DAQJobConfig</a>]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.info"><code class="name">var <span class="ident">info</span> : <a title="enrgdaq.daq.models.DAQJobInfo" href="models.html#enrgdaq.daq.models.DAQJobInfo">DAQJobInfo</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.instance_id"><code class="name">var <span class="ident">instance_id</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.message_in"><code class="name">var <span class="ident">message_in</span> : Any</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.message_out"><code class="name">var <span class="ident">message_out</span> : Any</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.multiprocessing_method"><code class="name">var <span class="ident">multiprocessing_method</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.restart_offset"><code class="name">var <span class="ident">restart_offset</span> : datetime.timedelta</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.topics_to_subscribe"><code class="name">var <span class="ident">topics_to_subscribe</span> : list[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.unique_id"><code class="name">var <span class="ident">unique_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.watchdog_force_exit"><code class="name">var <span class="ident">watchdog_force_exit</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.watchdog_timeout_seconds"><code class="name">var <span class="ident">watchdog_timeout_seconds</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="enrgdaq.daq.base.DAQJob.supervisor_id"><code class="name">prop <span class="ident">supervisor_id</span></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def supervisor_id(self):
    if self.info.supervisor_info is None:
        return &#34;unknown&#34;
    return self.info.supervisor_info.supervisor_id</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="enrgdaq.daq.base.DAQJob.free"><code class="name flex">
<span>def <span class="ident">free</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def free(self):
    if self._has_been_freed:
        return
    self._has_been_freed = True
    self.__del__()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.get_job_started_message"><code class="name flex">
<span>def <span class="ident">get_job_started_message</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_job_started_message(self):
    return self._prepare_message(DAQJobMessageJobStarted())</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.get_latency_stats"><code class="name flex">
<span>def <span class="ident">get_latency_stats</span></span>(<span>self) ‑> Any</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_latency_stats(self) -&gt; Any:
    if not self._latency_samples:
        return DAQJobLatencyStats()

    samples = sorted(self._latency_samples)
    count = len(samples)
    return DAQJobLatencyStats(
        count=self._processed_count,
        min_ms=samples[0],
        max_ms=samples[-1],
        avg_ms=sum(samples) / count,
        p95_ms=samples[int(count * 0.95)],
        p99_ms=samples[int(count * 0.99)],
    )</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.handle_message"><code class="name flex">
<span>def <span class="ident">handle_message</span></span>(<span>self, message: DAQJobMessage) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def handle_message(self, message: &#34;DAQJobMessage&#34;) -&gt; bool:
    &#34;&#34;&#34;
    Handles a message received from the message queue.

    Args:
        message (DAQJobMessage): The message to handle.

    Returns:
        bool: True if the message was handled, False otherwise.

    Raises:
        DAQJobStopError: If the message is a DAQJobMessageStop.
        Exception: If the message is not accepted by the job.
    &#34;&#34;&#34;

    if isinstance(message, DAQJobMessageStop):
        self.free()
        raise DAQJobStopError(message.reason)
    # check if the message is accepted
    is_message_type_accepted = False
    for accepted_message_type in self.allowed_message_in_types:
        if isinstance(message, accepted_message_type):
            is_message_type_accepted = True
    if not is_message_type_accepted:
        raise Exception(
            f&#34;Message type &#39;{type(message)}&#39; is not accepted by &#39;{type(self).__name__}&#39;&#34;
        )

    self._processed_count += 1

    if message.timestamp and isinstance(message, DAQJobMessageStore):
        latency = (datetime.now() - message.timestamp).total_seconds() * 1000.0
        self._latency_samples.append(latency)

        # Keep only last 1000 samples
        if len(self._latency_samples) &gt; 1000:
            self._latency_samples.pop(0)

    return True</code></pre>
</details>
<div class="desc"><p>Handles a message received from the message queue.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>message</code></strong> :&ensp;<code>DAQJobMessage</code></dt>
<dd>The message to handle.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if the message was handled, False otherwise.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>DAQJobStopError</code></dt>
<dd>If the message is a DAQJobMessageStop.</dd>
<dt><code>Exception</code></dt>
<dd>If the message is not accepted by the job.</dd>
</dl></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.report_stats"><code class="name flex">
<span>def <span class="ident">report_stats</span></span>(<span>self, force: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def report_stats(self, force: bool = False):
    if (
        not force
        and (datetime.now() - self._last_stats_report_time).total_seconds()
        &lt; DAQ_JOB_STATS_REPORT_INTERVAL_SECONDS
    ):
        return

    self._last_stats_report_time = datetime.now()
    report = DAQJobMessageStatsReport(
        processed_count=self._processed_count,
        processed_bytes=self._processed_bytes,
        sent_count=self._sent_count,
        sent_bytes=self._sent_bytes,
        latency=self.get_latency_stats(),
    )
    self._put_message_out(report)
    self._latency_samples = []  # RESET after report to get interval stats</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.report_traces"><code class="name flex">
<span>def <span class="ident">report_traces</span></span>(<span>self, force: bool = False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def report_traces(self, force: bool = False):
    if (
        not force
        and (datetime.now() - self._last_trace_report_time).total_seconds()
        &lt; DAQ_JOB_TRACE_REPORT_INTERVAL_SECONDS
    ):
        return

    if not self._trace_events:
        return

    self._last_trace_report_time = datetime.now()
    report = DAQJobMessageTraceReport(events=self._trace_events.copy())
    self._put_message_out(report)
    self._trace_events.clear()</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJob.start"><code class="name flex">
<span>def <span class="ident">start</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start(self):
    raise NotImplementedError</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess"><code class="flex name class">
<span>class <span class="ident">DAQJobProcess</span></span>
<span>(</span><span>*,<br>daq_job_cls: type[<a title="enrgdaq.daq.base.DAQJob" href="#enrgdaq.daq.base.DAQJob">DAQJob</a>],<br>supervisor_info: <a title="enrgdaq.models.SupervisorInfo" href="../models.html#enrgdaq.models.SupervisorInfo">SupervisorInfo</a>,<br>config: <a title="enrgdaq.daq.models.DAQJobConfig" href="models.html#enrgdaq.daq.models.DAQJobConfig">DAQJobConfig</a>,<br>process: multiprocessing.context.Process | None,<br>start_time: datetime.datetime = &lt;factory&gt;,<br>instance_id: int,<br>daq_job_info: <a title="enrgdaq.daq.models.DAQJobInfo" href="models.html#enrgdaq.daq.models.DAQJobInfo">DAQJobInfo</a> | None = None,<br>raw_config: str | None = None,<br>log_queue: typing.Any | None = None,<br>restart_on_crash: bool = True,<br>zmq_xpub_url: str | None = None,<br>zmq_xsub_url: str | None = None,<br>job_started_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7f2802e53380>> = &lt;factory&gt;)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"><p>A base class for defining efficient serializable objects.</p>
<p>Fields are defined using type annotations. Fields may optionally have
default values, which result in keyword parameters to the constructor.</p>
<p>Structs automatically define <code>__init__</code>, <code>__eq__</code>, <code>__repr__</code>, and
<code>__copy__</code> methods. Additional methods can be defined on the class as
needed. Note that <code>__init__</code>/<code>__new__</code> cannot be overridden, but other
methods can. A tuple of the field names is available on the class via the
<code>__struct_fields__</code> attribute if needed.</p>
<p>Additional class options can be enabled by passing keywords to the class
definition (see example below). These configuration options may also be
inspected at runtime through the <code>__struct_config__</code> attribute.</p>
<h2 id="configuration">Configuration</h2>
<p>frozen: bool, default False
Whether instances of this type are pseudo-immutable. If true, attribute
assignment is disabled and a corresponding <code>__hash__</code> is defined.
order: bool, default False
If True, <code>__lt__</code>, `<strong>le</strong><code>, </code><strong>gt</strong><code>, and </code><strong>ge</strong>`` methods
will be generated for this type.
eq: bool, default True
If True (the default), an <code>__eq__</code> method will be generated for this
type. Set to False to compare based on instance identity alone.
kw_only: bool, default False
If True, all fields will be treated as keyword-only arguments in the
generated <code>__init__</code> method. Default is False.
omit_defaults: bool, default False
Whether fields should be omitted from encoding if the corresponding value
is the default for that field. Enabling this may reduce message size, and
often also improve encoding &amp; decoding performance.
forbid_unknown_fields: bool, default False
If True, an error is raised if an unknown field is encountered while
decoding structs of this type. If False (the default), no error is raised
and the unknown field is skipped.
tag: str, int, bool, callable, or None, default None
Used along with <code>tag_field</code> for configuring tagged union support. If
either are non-None, then the struct is considered "tagged". In this case,
an extra field (the <code>tag_field</code>) and value (the <code>tag</code>) are added to the
encoded message, which can be used to differentiate message types during
decoding.</p>
<p>Set <code>tag=True</code> to enable the default tagged configuration (<code>tag_field</code>
is <code>"type"</code>, <code>tag</code> is the class name). Alternatively, you can provide
a string (or less commonly int) value directly to be used as the tag
(e.g. <code>tag="my-tag-value"</code>).<code>tag</code> can also be passed a callable that
takes the class qualname and returns a valid tag value (e.g.
<code>tag=str.lower</code>). See the docs for more information.
tag_field: str or None, default None
The field name to use for tagged union support. If <code>tag</code> is non-None,
then this defaults to <code>"type"</code>. See the <code>tag</code> docs above for more
information.
rename: str, mapping, callable, or None, default None
Controls renaming the field names used when encoding/decoding the struct.
May be one of <code>"lower"</code>, <code>"upper"</code>, <code>"camel"</code>, <code>"pascal"</code>, or
<code>"kebab"</code> to rename in lowercase, UPPERCASE, camelCase, PascalCase,
or kebab-case respectively. May also be a mapping from field names to the
renamed names (missing fields are not renamed). Alternatively, may be a
callable that takes the field name and returns a new name or <code>None</code> to
not rename that field. Default is <code>None</code> for no field renaming.
repr_omit_defaults: bool, default False
Whether fields should be omitted from the generated repr if the
corresponding value is the default for that field.
array_like: bool, default False
If True, this struct type will be treated as an array-like type during
encoding/decoding, rather than a dict-like type (the default). This may
improve performance, at the cost of a more inscrutable message encoding.
gc: bool, default True
Whether garbage collection is enabled for this type. Disabling this <em>may</em>
help reduce GC pressure, but will prevent reference cycles composed of only
<code>gc=False</code> from being collected. It is the user's responsibility to ensure
that reference cycles don't occur when setting <code>gc=False</code>.
weakref: bool, default False
Whether instances of this type support weak references. Defaults to False.
dict: bool, default False
Whether instances of this type will include a <code>__dict__</code>. Setting this to
True will allow adding additional undeclared attributes to a struct instance,
which may be useful for holding private runtime state. Defaults to False.
cache_hash: bool, default False
If enabled, the hash of a frozen struct instance will be computed at most
once, and then cached on the instance for further reuse. For expensive
hash values this can improve performance at the cost of a small amount of
memory usage.</p>
<h2 id="examples">Examples</h2>
<p>Here we define a new <code>Struct</code> type for describing a dog. It has three fields;
two required and one optional.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; class Dog(Struct):
...     name: str
...     breed: str
...     is_good_boy: bool = True
...
&gt;&gt;&gt; Dog('snickers', breed='corgi')
Dog(name='snickers', breed='corgi', is_good_boy=True)
</code></pre>
<p>Additional struct options can be set as part of the class definition. Here
we define a new <code>Struct</code> type for a frozen <code>Point</code> object.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; class Point(Struct, frozen=True):
...     x: float
...     y: float
...
&gt;&gt;&gt; {Point(1.5, 2.0): 1}  # frozen structs are hashable
{Point(x=1.5, y=2.0): 1}
</code></pre></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>msgspec.Struct</li>
<li>msgspec._core._StructMixin</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="enrgdaq.daq.base.DAQJobProcess.config"><code class="name">var <span class="ident">config</span> : <a title="enrgdaq.daq.models.DAQJobConfig" href="models.html#enrgdaq.daq.models.DAQJobConfig">DAQJobConfig</a></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.daq_job_cls"><code class="name">var <span class="ident">daq_job_cls</span> : type[<a title="enrgdaq.daq.base.DAQJob" href="#enrgdaq.daq.base.DAQJob">DAQJob</a>]</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.daq_job_info"><code class="name">var <span class="ident">daq_job_info</span> : <a title="enrgdaq.daq.models.DAQJobInfo" href="models.html#enrgdaq.daq.models.DAQJobInfo">DAQJobInfo</a> | None</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.instance_id"><code class="name">var <span class="ident">instance_id</span> : int</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.job_started_queue"><code class="name">var <span class="ident">job_started_queue</span> : <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x7f2802e53380>></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.log_queue"><code class="name">var <span class="ident">log_queue</span> : typing.Any | None</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.process"><code class="name">var <span class="ident">process</span> : multiprocessing.context.Process | None</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.raw_config"><code class="name">var <span class="ident">raw_config</span> : str | None</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.restart_on_crash"><code class="name">var <span class="ident">restart_on_crash</span> : bool</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.start_time"><code class="name">var <span class="ident">start_time</span> : datetime.datetime</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.supervisor_info"><code class="name">var <span class="ident">supervisor_info</span> : <a title="enrgdaq.models.SupervisorInfo" href="../models.html#enrgdaq.models.SupervisorInfo">SupervisorInfo</a></code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.zmq_xpub_url"><code class="name">var <span class="ident">zmq_xpub_url</span> : str | None</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.daq.base.DAQJobProcess.zmq_xsub_url"><code class="name">var <span class="ident">zmq_xsub_url</span> : str | None</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DAQJobProcess(msgspec.Struct, kw_only=True):
    daq_job_cls: type[DAQJob]
    supervisor_info: SupervisorInfo
    config: DAQJobConfig
    process: Process | None
    start_time: datetime = msgspec.field(default_factory=datetime.now)
    instance_id: int
    daq_job_info: DAQJobInfo | None = None
    raw_config: str | None = None
    log_queue: Any | None = None
    restart_on_crash: bool = True

    zmq_xpub_url: str | None = None
    zmq_xsub_url: str | None = None

    job_started_queue: multiprocessing.Queue = msgspec.field(
        default_factory=multiprocessing.Queue
    )

    def start(self):
        if self.log_queue:
            root_logger = logging.getLogger()
            root_logger.handlers.clear()
            root_logger.addHandler(QueueHandler(self.log_queue))
            root_logger.setLevel(logging.DEBUG)

        instance = self.daq_job_cls(
            self.config,
            supervisor_info=self.supervisor_info,
            instance_id=self.instance_id,
            raw_config=self.raw_config,
            zmq_xpub_url=self.zmq_xpub_url,
            zmq_xsub_url=self.zmq_xsub_url,
        )
        self.job_started_queue.put(instance.get_job_started_message())

        try:
            instance.start()
        except Exception as e:
            logging.error(
                f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
            )
            raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="enrgdaq.daq.base.DAQJobProcess.start"><code class="name flex">
<span>def <span class="ident">start</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start(self):
    if self.log_queue:
        root_logger = logging.getLogger()
        root_logger.handlers.clear()
        root_logger.addHandler(QueueHandler(self.log_queue))
        root_logger.setLevel(logging.DEBUG)

    instance = self.daq_job_cls(
        self.config,
        supervisor_info=self.supervisor_info,
        instance_id=self.instance_id,
        raw_config=self.raw_config,
        zmq_xpub_url=self.zmq_xpub_url,
        zmq_xsub_url=self.zmq_xsub_url,
    )
    self.job_started_queue.put(instance.get_job_started_message())

    try:
        instance.start()
    except Exception as e:
        logging.error(
            f&#34;Error on {self.daq_job_cls.__name__}.start(): {e}&#34;, exc_info=True
        )
        raise e</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="enrgdaq.daq" href="index.html">enrgdaq.daq</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="enrgdaq.daq.base.DAQJob" href="#enrgdaq.daq.base.DAQJob">DAQJob</a></code></h4>
<ul class="">
<li><code><a title="enrgdaq.daq.base.DAQJob.allowed_message_in_types" href="#enrgdaq.daq.base.DAQJob.allowed_message_in_types">allowed_message_in_types</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.config" href="#enrgdaq.daq.base.DAQJob.config">config</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.config_type" href="#enrgdaq.daq.base.DAQJob.config_type">config_type</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.free" href="#enrgdaq.daq.base.DAQJob.free">free</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.get_job_started_message" href="#enrgdaq.daq.base.DAQJob.get_job_started_message">get_job_started_message</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.get_latency_stats" href="#enrgdaq.daq.base.DAQJob.get_latency_stats">get_latency_stats</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.handle_message" href="#enrgdaq.daq.base.DAQJob.handle_message">handle_message</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.info" href="#enrgdaq.daq.base.DAQJob.info">info</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.instance_id" href="#enrgdaq.daq.base.DAQJob.instance_id">instance_id</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.message_in" href="#enrgdaq.daq.base.DAQJob.message_in">message_in</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.message_out" href="#enrgdaq.daq.base.DAQJob.message_out">message_out</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.multiprocessing_method" href="#enrgdaq.daq.base.DAQJob.multiprocessing_method">multiprocessing_method</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.report_stats" href="#enrgdaq.daq.base.DAQJob.report_stats">report_stats</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.report_traces" href="#enrgdaq.daq.base.DAQJob.report_traces">report_traces</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.restart_offset" href="#enrgdaq.daq.base.DAQJob.restart_offset">restart_offset</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.start" href="#enrgdaq.daq.base.DAQJob.start">start</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.supervisor_id" href="#enrgdaq.daq.base.DAQJob.supervisor_id">supervisor_id</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.topics_to_subscribe" href="#enrgdaq.daq.base.DAQJob.topics_to_subscribe">topics_to_subscribe</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.unique_id" href="#enrgdaq.daq.base.DAQJob.unique_id">unique_id</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.watchdog_force_exit" href="#enrgdaq.daq.base.DAQJob.watchdog_force_exit">watchdog_force_exit</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJob.watchdog_timeout_seconds" href="#enrgdaq.daq.base.DAQJob.watchdog_timeout_seconds">watchdog_timeout_seconds</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="enrgdaq.daq.base.DAQJobProcess" href="#enrgdaq.daq.base.DAQJobProcess">DAQJobProcess</a></code></h4>
<ul class="two-column">
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.config" href="#enrgdaq.daq.base.DAQJobProcess.config">config</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.daq_job_cls" href="#enrgdaq.daq.base.DAQJobProcess.daq_job_cls">daq_job_cls</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.daq_job_info" href="#enrgdaq.daq.base.DAQJobProcess.daq_job_info">daq_job_info</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.instance_id" href="#enrgdaq.daq.base.DAQJobProcess.instance_id">instance_id</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.job_started_queue" href="#enrgdaq.daq.base.DAQJobProcess.job_started_queue">job_started_queue</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.log_queue" href="#enrgdaq.daq.base.DAQJobProcess.log_queue">log_queue</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.process" href="#enrgdaq.daq.base.DAQJobProcess.process">process</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.raw_config" href="#enrgdaq.daq.base.DAQJobProcess.raw_config">raw_config</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.restart_on_crash" href="#enrgdaq.daq.base.DAQJobProcess.restart_on_crash">restart_on_crash</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.start" href="#enrgdaq.daq.base.DAQJobProcess.start">start</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.start_time" href="#enrgdaq.daq.base.DAQJobProcess.start_time">start_time</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.supervisor_info" href="#enrgdaq.daq.base.DAQJobProcess.supervisor_info">supervisor_info</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.zmq_xpub_url" href="#enrgdaq.daq.base.DAQJobProcess.zmq_xpub_url">zmq_xpub_url</a></code></li>
<li><code><a title="enrgdaq.daq.base.DAQJobProcess.zmq_xsub_url" href="#enrgdaq.daq.base.DAQJobProcess.zmq_xsub_url">zmq_xsub_url</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
