<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>enrgdaq.tools.benchmark_runner API documentation</title>
<meta name="description" content="ENRGDAQ Benchmark Script …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>enrgdaq.tools.benchmark_runner</code></h1>
</header>
<section id="section-intro">
<p>ENRGDAQ Benchmark Script</p>
<p>This script benchmarks the ENRGDAQ system by running multiple supervisor instances
with benchmark jobs that stress test message throughput, serialization, and networking.</p>
<h2 id="usage">Usage</h2>
<p>python benchmark.py [&ndash;clients N] [&ndash;payload-size N] [&ndash;duration SECONDS]</p>
<h2 id="example">Example</h2>
<p>python benchmark.py &ndash;clients 5 &ndash;payload-size 10000 &ndash;duration 30</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.cleanup_supervisor"><code class="name flex">
<span>def <span class="ident">cleanup_supervisor</span></span>(<span>supervisor: <a title="enrgdaq.supervisor.Supervisor" href="../supervisor.html#enrgdaq.supervisor.Supervisor">Supervisor</a>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_supervisor(supervisor: Supervisor):
    &#34;&#34;&#34;Clean up supervisor and all its child processes.&#34;&#34;&#34;
    try:
        supervisor.stop()
        # Give a moment for clean shutdown
        time.sleep(0.1)
        # Force kill any remaining DAQ job processes
        for process in supervisor.daq_job_processes:
            if process.process and process.process.is_alive() and process.process.pid:
                kill_process_tree(process.process.pid)
    except Exception:
        pass</code></pre>
</details>
<div class="desc"><p>Clean up supervisor and all its child processes.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.create_supervisor_config"><code class="name flex">
<span>def <span class="ident">create_supervisor_config</span></span>(<span>supervisor_id: str) ‑> <a title="enrgdaq.models.SupervisorConfig" href="../models.html#enrgdaq.models.SupervisorConfig">SupervisorConfig</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_supervisor_config(supervisor_id: str) -&gt; SupervisorConfig:
    &#34;&#34;&#34;Create a SupervisorConfig instance.&#34;&#34;&#34;
    return SupervisorConfig(info=create_supervisor_info(supervisor_id))</code></pre>
</details>
<div class="desc"><p>Create a SupervisorConfig instance.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.create_supervisor_info"><code class="name flex">
<span>def <span class="ident">create_supervisor_info</span></span>(<span>supervisor_id: str) ‑> <a title="enrgdaq.models.SupervisorInfo" href="../models.html#enrgdaq.models.SupervisorInfo">SupervisorInfo</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_supervisor_info(supervisor_id: str) -&gt; SupervisorInfo:
    &#34;&#34;&#34;Create a SupervisorInfo instance.&#34;&#34;&#34;
    return SupervisorInfo(supervisor_id=supervisor_id)</code></pre>
</details>
<div class="desc"><p>Create a SupervisorInfo instance.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.kill_process_tree"><code class="name flex">
<span>def <span class="ident">kill_process_tree</span></span>(<span>pid: int, sig=15)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kill_process_tree(pid: int, sig=signal.SIGTERM):
    &#34;&#34;&#34;Kill a process and all its children using psutil.&#34;&#34;&#34;
    try:
        parent = psutil.Process(pid)
        children = parent.children(recursive=True)

        # Kill children first
        for child in children:
            try:
                child.send_signal(sig)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass

        # Kill parent
        try:
            parent.send_signal(sig)
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass

        # Wait for processes to terminate
        gone, alive = psutil.wait_procs(children + [parent], timeout=1)

        # Force kill any remaining
        for p in alive:
            try:
                p.kill()
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass

    except psutil.NoSuchProcess:
        pass</code></pre>
</details>
<div class="desc"><p>Kill a process and all its children using psutil.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.parse_args"><code class="name flex">
<span>def <span class="ident">parse_args</span></span>(<span>) ‑> <a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_args() -&gt; BenchmarkConfig:
    &#34;&#34;&#34;Parse command line arguments.&#34;&#34;&#34;
    parser = argparse.ArgumentParser(
        description=&#34;ENRGDAQ Benchmark Script&#34;,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=&#34;&#34;&#34;
Examples:
  python benchmark.py                           # Run with defaults
  python benchmark.py --clients 10              # Run with 10 clients
  python benchmark.py --payload-size 50000      # Larger payloads
  python benchmark.py --duration 120            # Run for 2 minutes
        &#34;&#34;&#34;,
    )
    parser.add_argument(
        &#34;--clients&#34;,
        type=int,
        default=DEFAULT_NUM_CLIENTS,
        help=f&#34;Number of benchmark clients (default: {DEFAULT_NUM_CLIENTS})&#34;,
    )
    parser.add_argument(
        &#34;--payload-size&#34;,
        type=int,
        default=DEFAULT_PAYLOAD_SIZE,
        help=f&#34;Number of values per message (default: {DEFAULT_PAYLOAD_SIZE})&#34;,
    )
    parser.add_argument(
        &#34;--duration&#34;,
        type=int,
        default=DEFAULT_DURATION_SECONDS,
        help=f&#34;Benchmark duration in seconds (default: {DEFAULT_DURATION_SECONDS})&#34;,
    )
    parser.add_argument(
        &#34;--stats-interval&#34;,
        type=float,
        default=DEFAULT_STATS_INTERVAL_SECONDS,
        help=f&#34;Stats collection interval in seconds (default: {DEFAULT_STATS_INTERVAL_SECONDS})&#34;,
    )
    parser.add_argument(
        &#34;--zmq-xsub&#34;,
        type=str,
        default=DEFAULT_ZMQ_XSUB_URL,
        help=f&#34;ZMQ XSUB URL (default: {DEFAULT_ZMQ_XSUB_URL})&#34;,
    )
    parser.add_argument(
        &#34;--zmq-xpub&#34;,
        type=str,
        default=DEFAULT_ZMQ_XPUB_URL,
        help=f&#34;ZMQ XPUB URL (default: {DEFAULT_ZMQ_XPUB_URL})&#34;,
    )
    parser.add_argument(
        &#34;--no-void-data&#34;,
        action=&#34;store_true&#34;,
        help=&#34;Don&#39;t void memory store data (uses more memory)&#34;,
    )
    parser.add_argument(
        &#34;--use-shm&#34;, action=&#34;store_true&#34;, default=True, help=&#34;Use SHM for zero-copy&#34;
    )
    parser.add_argument(
        &#34;--no-shm&#34;, action=&#34;store_false&#34;, dest=&#34;use_shm&#34;, help=&#34;Disable SHM&#34;
    )
    parser.add_argument(
        &#34;--use-memory-store&#34;,
        action=&#34;store_true&#34;,
        help=&#34;Use Memory store instead of ROOT store&#34;,
    )

    args = parser.parse_args()

    return BenchmarkConfig(
        num_clients=args.clients,
        payload_size=args.payload_size,
        duration_seconds=args.duration,
        stats_interval_seconds=args.stats_interval,
        zmq_xsub_url=args.zmq_xsub,
        zmq_xpub_url=args.zmq_xpub,
        void_memory_data=not args.no_void_data,
        use_memory_store=args.use_memory_store,
        use_shm=args.use_shm,
    )</code></pre>
</details>
<div class="desc"><p>Parse command line arguments.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.run_client_supervisor"><code class="name flex">
<span>def <span class="ident">run_client_supervisor</span></span>(<span>client_id: int,<br>config: <a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a>,<br>stop_flag: <bound method BaseContext.Value of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>>,<br>ready_event: <bound method BaseContext.Event of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>>,<br>shm_bytes_counter: <bound method BaseContext.Array of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_client_supervisor(
    client_id: int,
    config: BenchmarkConfig,
    stop_flag: Value,
    ready_event: Event,
    shm_bytes_counter: Array,
):
    &#34;&#34;&#34;Run a client supervisor that generates benchmark data.&#34;&#34;&#34;

    # Create temporary config directory for the supervisor
    temp_config_dir = tempfile.mkdtemp(prefix=&#34;enrgdaq_benchmark_client_&#34;)

    supervisor_id = f&#34;benchmark_client_{client_id}&#34;
    supervisor_info = create_supervisor_info(supervisor_id)
    supervisor_config = create_supervisor_config(supervisor_id)
    supervisor_config.ring_buffer_size_mb = 1024  # 1GB for clients
    supervisor_config.ring_buffer_slot_size_kb = 10 * 1024  # 10MB slots

    daq_job_processes = [
        # Benchmark job that generates data
        _create_daq_job_process(
            DAQJobBenchmark,
            DAQJobBenchmarkConfig(
                daq_job_type=&#34;DAQJobBenchmark&#34;,
                payload_size=config.payload_size,
                use_shm=config.use_shm,
                store_config=DAQJobStoreConfig(memory=DAQJobStoreConfigMemory())
                if config.use_memory_store
                else DAQJobStoreConfig(
                    root=DAQJobStoreConfigROOT(
                        file_path=&#34;test.root&#34;,
                        add_date=False,
                        tree_name=&#34;benchmark_tree&#34;,
                    )
                ),
            ),
            supervisor_info,
        ),
        # Remote job for sending to main supervisor
        _create_daq_job_process(
            DAQJobRemote,
            DAQJobRemoteConfig(
                daq_job_type=&#34;DAQJobRemote&#34;,
                zmq_proxy_sub_urls=[],
                zmq_proxy_pub_url=config.zmq_xsub_url,
            ),
            supervisor_info,
        ),
    ]

    supervisor = Supervisor(
        config=supervisor_config,
        daq_job_processes=daq_job_processes,
        daq_job_config_path=temp_config_dir,
    )

    # Register cleanup on exit
    atexit.register(cleanup_supervisor, supervisor)

    # Initialize supervisor and signal ready
    supervisor.init()
    ready_event.set()  # Signal that this client is ready

    run_supervisor_with_stats(
        supervisor,
        config,
        None,
        stop_flag,
        collect_stats=False,
        skip_init=True,
        shm_bytes_counter=shm_bytes_counter,
        client_id=client_id,
    )</code></pre>
</details>
<div class="desc"><p>Run a client supervisor that generates benchmark data.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.run_main_supervisor"><code class="name flex">
<span>def <span class="ident">run_main_supervisor</span></span>(<span>config: <a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a>,<br>stats_queue: Any,<br>stop_flag: <bound method BaseContext.Value of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>>,<br>client_shm_bytes: <bound method BaseContext.Array of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_main_supervisor(
    config: BenchmarkConfig,
    stats_queue: Any,
    stop_flag: Value,
    client_shm_bytes: Array,
):
    &#34;&#34;&#34;Run the main supervisor that collects stats and runs the proxy.&#34;&#34;&#34;

    # Create temporary config directory for the supervisor
    temp_config_dir = tempfile.mkdtemp(prefix=&#34;enrgdaq_benchmark_&#34;)

    supervisor_id = &#34;benchmark_supervisor&#34;
    supervisor_info = create_supervisor_info(supervisor_id)
    supervisor_config = create_supervisor_config(supervisor_id)
    supervisor_config.ring_buffer_size_mb = 1024
    supervisor_config.ring_buffer_slot_size_kb = 10 * 1024

    # Create DAQ job processes using the proper factory function
    daq_job_processes = []

    # Main store - either Memory (fast, for testing) or ROOT (slow, for production)
    if config.use_memory_store:
        daq_job_processes.append(
            _create_daq_job_process(
                DAQJobStoreMemory,
                DAQJobStoreMemoryConfig(
                    daq_job_type=&#34;DAQJobStoreMemory&#34;,
                    void_data=config.void_memory_data,
                ),
                supervisor_info,
            )
        )
    else:
        daq_job_processes.append(
            _create_daq_job_process(
                DAQJobStoreROOT,
                DAQJobStoreROOTConfig(
                    daq_job_type=&#34;DAQJobStoreROOT&#34;, verbosity=LogVerbosity.DEBUG
                ),
                supervisor_info,
            )
        )
    # CSV store for stats output
    daq_job_processes.append(
        _create_daq_job_process(
            DAQJobStoreCSV,
            DAQJobStoreCSVConfig(daq_job_type=&#34;DAQJobStoreCSV&#34;),
            supervisor_info,
        )
    )
    # Remote job for receiving from clients
    daq_job_processes.append(
        _create_daq_job_process(
            DAQJobRemote,
            DAQJobRemoteConfig(
                daq_job_type=&#34;DAQJobRemote&#34;,
                zmq_proxy_sub_urls=[config.zmq_xpub_url],
            ),
            supervisor_info,
        )
    )
    # Stats handler
    daq_job_processes.append(
        _create_daq_job_process(
            DAQJobHandleStats,
            DAQJobHandleStatsConfig(
                daq_job_type=&#34;DAQJobHandleStats&#34;,
                store_config=DAQJobStoreConfig(
                    csv=DAQJobStoreConfigCSV(
                        file_path=config.output_stats_csv,
                        overwrite=True,
                    ),
                ),
            ),
            supervisor_info,
        )
    )
    # Remote proxy (XSUB/XPUB)
    daq_job_processes.append(
        _create_daq_job_process(
            DAQJobRemoteProxy,
            DAQJobRemoteProxyConfig(
                daq_job_type=&#34;DAQJobRemoteProxy&#34;,
                zmq_xsub_url=config.zmq_xsub_url,
                zmq_xpub_url=config.zmq_xpub_url,
            ),
            supervisor_info,
        )
    )

    supervisor = Supervisor(
        config=supervisor_config,
        daq_job_processes=daq_job_processes,
        daq_job_config_path=temp_config_dir,
    )

    # Register cleanup on exit
    atexit.register(cleanup_supervisor, supervisor)

    run_supervisor_with_stats(
        supervisor, config, stats_queue, stop_flag, client_shm_bytes=client_shm_bytes
    )</code></pre>
</details>
<div class="desc"><p>Run the main supervisor that collects stats and runs the proxy.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.run_supervisor_with_stats"><code class="name flex">
<span>def <span class="ident">run_supervisor_with_stats</span></span>(<span>supervisor: <a title="enrgdaq.supervisor.Supervisor" href="../supervisor.html#enrgdaq.supervisor.Supervisor">Supervisor</a>,<br>config: <a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a>,<br>stats_queue: Any,<br>stop_flag: <bound method BaseContext.Value of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>>,<br>collect_stats: bool = True,<br>skip_init: bool = False,<br>shm_bytes_counter: <bound method BaseContext.Array of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>> | None = None,<br>client_id: int | None = None,<br>client_shm_bytes: <bound method BaseContext.Array of <multiprocessing.context.DefaultContext object at 0x7f8cf1ce3350>> | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_supervisor_with_stats(
    supervisor: Supervisor,
    config: BenchmarkConfig,
    stats_queue: Any,
    stop_flag: Value,
    collect_stats: bool = True,
    skip_init: bool = False,
    shm_bytes_counter: Optional[Array] = None,
    client_id: Optional[int] = None,
    client_shm_bytes: Optional[Array] = None,
):
    &#34;&#34;&#34;Run a supervisor and optionally collect stats.&#34;&#34;&#34;
    assert supervisor.config is not None

    if not skip_init:
        supervisor.init()

    # Start supervisor in a separate thread
    supervisor_thread = Thread(target=supervisor.run, daemon=True)
    supervisor_thread.start()

    try:
        if not collect_stats or stats_queue is None:
            # Just keep the process alive
            while not stop_flag.value:
                time.sleep(0.5)
        else:
            # Collect and report stats
            last_stats: Optional[dict] = None
            last_iteration = datetime.now()

            while not stop_flag.value:
                # Get stats from remote stats dict
                stats_list = [
                    v
                    for k, v in supervisor.daq_job_remote_stats.items()
                    if k == supervisor.config.info.supervisor_id
                ]

                # Calculate current stats
                msg_in_out_mb = (
                    sum([x.message_in_bytes + x.message_out_bytes for x in stats_list])
                    / 10**6
                    if stats_list
                    else 0.0
                )
                msg_in_count = (
                    sum([x.message_in_count for x in stats_list]) if stats_list else 0
                )
                msg_out_count = (
                    sum([x.message_out_count for x in stats_list]) if stats_list else 0
                )

                # Calculate queue sizes (macOS doesn&#39;t support qsize, so use fallback)
                try:
                    avg_queue_size = fmean(
                        [
                            x.message_out.qsize() + x.message_in.qsize()
                            for x in supervisor.daq_job_processes
                        ]
                    )
                except (NotImplementedError, Exception):
                    avg_queue_size = 0.0

                # Calculate active job count
                active_job_count = len(
                    [
                        x
                        for x in supervisor.daq_job_processes
                        if x.process and x.process.is_alive()
                    ]
                )

                # Calculate MB/s
                now = datetime.now()
                elapsed = (now - last_iteration).total_seconds()
                if last_stats and elapsed &gt; 0:
                    mb_diff = msg_in_out_mb - last_stats[&#34;msg_in_out_mb&#34;]
                    msg_in_out_mb_per_s = mb_diff / elapsed
                else:
                    msg_in_out_mb_per_s = 0.0

                # Calculate CPU and Memory usage
                cpu_usage = sum(
                    [
                        stats.resource_stats.cpu_percent
                        for stats in supervisor.daq_job_stats.values()
                    ]
                )
                rss_mb_total = sum(
                    [
                        stats.resource_stats.rss_mb
                        for stats in supervisor.daq_job_stats.values()
                    ]
                )

                # Calculate Latency (max of p95/p99 across jobs to be conservative)
                p95_latencies = [
                    stats.latency_stats.p95_ms
                    for stats in supervisor.daq_job_stats.values()
                    if stats.latency_stats.count &gt; 0
                ]
                p99_latencies = [
                    stats.latency_stats.p99_ms
                    for stats in supervisor.daq_job_stats.values()
                    if stats.latency_stats.count &gt; 0
                ]

                latency_p95 = max(p95_latencies) if p95_latencies else 0.0
                latency_p99 = max(p99_latencies) if p99_latencies else 0.0

                # Calculate data throughput from message count (more reliable than ring buffer stats)
                # Each message contains payload_size * 2 float64 columns (timestamp + value) = 16 bytes/row
                msg_size_bytes = config.payload_size * 16
                if last_stats and elapsed &gt; 0:
                    msg_diff = msg_in_count - last_stats.get(&#34;msg_in_count&#34;, 0)
                    data_mb_per_s = (msg_diff * msg_size_bytes) / elapsed / 10**6
                else:
                    data_mb_per_s = 0.0
                total_data_mb = msg_in_count * msg_size_bytes / 10**6

                current_stats = {
                    &#34;timestamp&#34;: now.isoformat(),
                    &#34;supervisor_id&#34;: supervisor.config.info.supervisor_id,
                    &#34;msg_in_out_mb&#34;: msg_in_out_mb,
                    &#34;msg_in_count&#34;: msg_in_count,
                    &#34;msg_out_count&#34;: msg_out_count,
                    &#34;msg_in_out_mb_per_s&#34;: msg_in_out_mb_per_s,
                    &#34;avg_queue_size&#34;: avg_queue_size,
                    &#34;active_job_count&#34;: active_job_count,
                    &#34;cpu_usage_percent&#34;: cpu_usage,
                    &#34;rss_mb&#34;: rss_mb_total,
                    &#34;latency_p95_ms&#34;: latency_p95,
                    &#34;latency_p99_ms&#34;: latency_p99,
                    &#34;shm_bytes_written&#34;: int(total_data_mb * 10**6),
                    &#34;shm_mb_per_s&#34;: data_mb_per_s,
                }

                try:
                    stats_queue.put_nowait(current_stats)
                except Exception:
                    pass

                last_stats = current_stats
                last_iteration = now

                time.sleep(config.stats_interval_seconds)
    finally:
        # Always clean up the supervisor
        cleanup_supervisor(supervisor)</code></pre>
</details>
<div class="desc"><p>Run a supervisor and optionally collect stats.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig"><code class="flex name class">
<span>class <span class="ident">BenchmarkConfig</span></span>
<span>(</span><span>num_clients: int = 5,<br>payload_size: int = 1000,<br>duration_seconds: int = 60,<br>stats_interval_seconds: float = 1,<br>zmq_xsub_url: str = 'tcp://localhost:10001',<br>zmq_xpub_url: str = 'tcp://localhost:10002',<br>output_stats_csv: str = 'benchmark_stats.csv',<br>output_remote_stats_csv: str = 'benchmark_remote_stats.csv',<br>void_memory_data: bool = True,<br>use_memory_store: bool = False,<br>use_shm: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class BenchmarkConfig:
    &#34;&#34;&#34;Configuration for benchmark run.&#34;&#34;&#34;

    num_clients: int = DEFAULT_NUM_CLIENTS
    payload_size: int = DEFAULT_PAYLOAD_SIZE
    duration_seconds: int = DEFAULT_DURATION_SECONDS
    stats_interval_seconds: float = DEFAULT_STATS_INTERVAL_SECONDS
    zmq_xsub_url: str = DEFAULT_ZMQ_XSUB_URL
    zmq_xpub_url: str = DEFAULT_ZMQ_XPUB_URL
    output_stats_csv: str = &#34;benchmark_stats.csv&#34;
    output_remote_stats_csv: str = &#34;benchmark_remote_stats.csv&#34;
    void_memory_data: bool = True
    use_memory_store: bool = False
    use_shm: bool = True</code></pre>
</details>
<div class="desc"><p>Configuration for benchmark run.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.duration_seconds"><code class="name">var <span class="ident">duration_seconds</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.num_clients"><code class="name">var <span class="ident">num_clients</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_remote_stats_csv"><code class="name">var <span class="ident">output_remote_stats_csv</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_stats_csv"><code class="name">var <span class="ident">output_stats_csv</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.payload_size"><code class="name">var <span class="ident">payload_size</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.stats_interval_seconds"><code class="name">var <span class="ident">stats_interval_seconds</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_memory_store"><code class="name">var <span class="ident">use_memory_store</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_shm"><code class="name">var <span class="ident">use_shm</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.void_memory_data"><code class="name">var <span class="ident">void_memory_data</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.zmq_xpub_url"><code class="name">var <span class="ident">zmq_xpub_url</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.zmq_xsub_url"><code class="name">var <span class="ident">zmq_xsub_url</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkRunner"><code class="flex name class">
<span>class <span class="ident">BenchmarkRunner</span></span>
<span>(</span><span>config: <a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BenchmarkRunner:
    &#34;&#34;&#34;Runs the ENRGDAQ benchmark and collects statistics.&#34;&#34;&#34;

    def __init__(self, config: BenchmarkConfig):
        self.config = config
        self._stats_queue: Any = _create_queue()
        self._stop_flag = Value(&#34;b&#34;, False)
        self._processes: list[Process] = []
        self._stats_history: list[BenchmarkStats] = []
        self._main_pid = os.getpid()

    def _dict_to_stats(self, d: dict) -&gt; BenchmarkStats:
        &#34;&#34;&#34;Convert dictionary to BenchmarkStats.&#34;&#34;&#34;
        return BenchmarkStats(
            timestamp=datetime.fromisoformat(d[&#34;timestamp&#34;]),
            supervisor_id=d[&#34;supervisor_id&#34;],
            msg_in_out_mb=d[&#34;msg_in_out_mb&#34;],
            msg_in_count=d[&#34;msg_in_count&#34;],
            msg_out_count=d[&#34;msg_out_count&#34;],
            msg_in_out_mb_per_s=d[&#34;msg_in_out_mb_per_s&#34;],
            avg_queue_size=d[&#34;avg_queue_size&#34;],
            active_job_count=d[&#34;active_job_count&#34;],
            cpu_usage_percent=d.get(&#34;cpu_usage_percent&#34;, 0.0),
            rss_mb=d.get(&#34;rss_mb&#34;, 0.0),
            latency_p95_ms=d.get(&#34;latency_p95_ms&#34;, 0.0),
            latency_p99_ms=d.get(&#34;latency_p99_ms&#34;, 0.0),
            shm_bytes_written=d.get(&#34;shm_bytes_written&#34;, 0),
            shm_mb_per_s=d.get(&#34;shm_mb_per_s&#34;, 0.0),
        )

    def _print_stats(self, stats: BenchmarkStats):
        &#34;&#34;&#34;Print statistics to console.&#34;&#34;&#34;
        print(
            f&#34;[{stats.timestamp.strftime(&#39;%H:%M:%S&#39;)}] &#34;
            f&#34;SHM: {stats.shm_mb_per_s:7.2f} MB/s | &#34;
            f&#34;CPU: {stats.cpu_usage_percent:5.1f}% | &#34;
            f&#34;p95 Latency: {stats.latency_p95_ms:5.2f}ms | &#34;
            f&#34;Active Jobs: {stats.active_job_count:3d}&#34;
        )

    def _handle_signal(self, signum, frame):
        &#34;&#34;&#34;Handle termination signals.&#34;&#34;&#34;
        print(&#34;\nReceived termination signal, stopping...&#34;)
        self._stop_flag.value = True

    def _cleanup_all_processes(self):
        &#34;&#34;&#34;Forcefully clean up all child processes using psutil.&#34;&#34;&#34;
        print(&#34;\nTerminating processes...&#34;)

        # First, signal all processes to stop gracefully
        self._stop_flag.value = True

        # Give processes time to clean up their children
        time.sleep(0.5)

        # Kill entire process tree for each child process
        for p in self._processes:
            if p.pid:
                kill_process_tree(p.pid)

        # Also terminate using Process API as backup
        for p in self._processes:
            try:
                if p.is_alive():
                    p.terminate()
            except Exception:
                pass

        # Wait for processes to terminate
        for p in self._processes:
            try:
                p.join(timeout=1)
            except Exception:
                pass

        # Force kill any remaining processes
        for p in self._processes:
            try:
                if p.is_alive():
                    p.kill()
            except Exception:
                pass

    def run(self):
        &#34;&#34;&#34;Run the benchmark.&#34;&#34;&#34;
        # Set up signal handlers
        signal.signal(signal.SIGINT, self._handle_signal)
        signal.signal(signal.SIGTERM, self._handle_signal)

        # Register cleanup on exit
        atexit.register(self._cleanup_all_processes)

        print(&#34;=&#34; * 80)
        print(&#34;ENRGDAQ Benchmark&#34;)
        print(&#34;=&#34; * 80)
        print(&#34;Configuration:&#34;)
        print(f&#34;  - Clients:        {self.config.num_clients}&#34;)
        print(f&#34;  - Payload Size:   {self.config.payload_size} values/message&#34;)
        print(f&#34;  - Duration:       {self.config.duration_seconds} seconds&#34;)
        print(f&#34;  - ZMQ XSUB URL:   {self.config.zmq_xsub_url}&#34;)
        print(f&#34;  - ZMQ XPUB URL:   {self.config.zmq_xpub_url}&#34;)
        print(&#34;=&#34; * 80)
        print()

        # Clean up any existing output files from previous runs
        output_files_to_clean = [&#34;out/test.root&#34;]
        for output_file in output_files_to_clean:
            if os.path.exists(output_file):
                os.remove(output_file)
                print(f&#34;Removed existing output file: {output_file}&#34;)

        # Create shared array to track client ring buffer bytes (one c_longlong per client)
        self._client_shm_bytes = Array(&#34;q&#34;, self.config.num_clients)  # &#39;q&#39; = c_longlong

        # Start main supervisor process
        print(&#34;Starting main supervisor...&#34;)
        main_process = Process(
            target=run_main_supervisor,
            args=(
                self.config,
                self._stats_queue,
                self._stop_flag,
                self._client_shm_bytes,
            ),
        )
        main_process.start()
        self._processes.append(main_process)

        # Give main supervisor time to start (ZMQ needs to bind first)
        time.sleep(1)

        # Create ready events for each client
        ready_events = [Event() for _ in range(self.config.num_clients)]

        # Start client processes
        print(f&#34;Starting {self.config.num_clients} client(s)...&#34;)
        for i in range(self.config.num_clients):
            client_process = Process(
                target=run_client_supervisor,
                args=(
                    i,
                    self.config,
                    self._stop_flag,
                    ready_events[i],
                    self._client_shm_bytes,
                ),
            )
            client_process.start()
            self._processes.append(client_process)

        # Wait for all clients to signal ready (with timeout)
        print(&#34;Waiting for clients to be ready...&#34;)
        all_ready = all(event.wait(timeout=30) for event in ready_events)
        if not all_ready:
            print(&#34;WARNING: Not all clients signaled ready within timeout&#34;)

        print()
        print(&#34;Benchmark running... (waiting for first data)&#34;)
        print(&#34;-&#34; * 80)

        # Timer starts when first data arrives, not now
        start_time: datetime | None = None
        end_time_seconds = self.config.duration_seconds

        try:
            while not self._stop_flag.value:
                # Check for stats in queue
                try:
                    stats_dict = self._stats_queue.get(timeout=0.5)
                    stats = self._dict_to_stats(stats_dict)

                    # Start timer when first data arrives
                    if start_time is None and stats.msg_in_count &gt; 0:
                        start_time = datetime.now()
                        print(&#34;First data received, starting timer...&#34;)

                    self._stats_history.append(stats)
                    self._print_stats(stats)
                except Exception:
                    pass

                # Check duration (only if timer has started)
                if start_time is not None:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    if elapsed &gt;= end_time_seconds:
                        print(f&#34;\nDuration of {end_time_seconds}s reached, stopping...&#34;)
                        break

        finally:
            self._stop_flag.value = True

            # Print summary
            self._print_summary()

            # Clean up all processes
            self._cleanup_all_processes()

            # Unregister atexit since we&#39;ve already cleaned up
            try:
                atexit.unregister(self._cleanup_all_processes)
            except Exception:
                pass

    def _print_summary(self):
        &#34;&#34;&#34;Print benchmark summary statistics.&#34;&#34;&#34;
        # Filter to stats with actual data, skipping the first 3 seconds of warmup
        data_stats = [s for s in self._stats_history if s.msg_in_count &gt; 0]
        if len(data_stats) &gt; 3:
            data_stats = data_stats[3:]

        if not data_stats:
            print(&#34;\nNo statistics collected.&#34;)
            return

        print()
        print(&#34;=&#34; * 80)
        print(&#34;Benchmark Summary&#34;)
        print(&#34;=&#34; * 80)

        # Calculate duration from first data to last data
        total_duration = (
            data_stats[-1].timestamp - data_stats[0].timestamp
        ).total_seconds()

        if total_duration &lt;= 0:
            total_duration = 1.0

        avg_throughput = fmean([s.msg_in_out_mb_per_s for s in data_stats])
        # max_throughput = max([s.msg_in_out_mb_per_s for s in data_stats])
        avg_shm_throughput = fmean([s.shm_mb_per_s for s in data_stats])
        max_shm_throughput = max([s.shm_mb_per_s for s in data_stats])
        total_shm_mb = data_stats[-1].shm_bytes_written / 10**6
        # total_mb = data_stats[-1].msg_in_out_mb
        total_msgs = data_stats[-1].msg_in_count
        avg_queue = fmean([s.avg_queue_size for s in data_stats])

        print(f&#34;Duration:              {total_duration:.1f} seconds&#34;)
        print(f&#34;Avg SHM Throughput:    {avg_shm_throughput:.2f} MB/s&#34;)
        print(f&#34;Peak SHM Throughput:   {max_shm_throughput:.2f} MB/s&#34;)
        print(f&#34;Total SHM Data:        {total_shm_mb:.2f} MB&#34;)
        print(f&#34;ZMQ Throughput:        {avg_throughput:.2f} MB/s (handles only)&#34;)
        print(f&#34;Total Messages:        {total_msgs:,}&#34;)
        print(f&#34;Average Queue Size:    {avg_queue:.1f}&#34;)
        print(f&#34;Messages/Second:       {total_msgs / total_duration:,.0f}&#34;)
        print(
            f&#34;Avg CPU Usage:         {fmean([s.cpu_usage_percent for s in data_stats]):.1f}%&#34;
        )
        print(
            f&#34;Avg p95 Latency:       {fmean([s.latency_p95_ms for s in data_stats]):.2f} ms&#34;
        )
        print(
            f&#34;Peak p99 Latency:      {max([s.latency_p99_ms for s in data_stats]):.2f} ms&#34;
        )
        print(&#34;=&#34; * 80)</code></pre>
</details>
<div class="desc"><p>Runs the ENRGDAQ benchmark and collects statistics.</p></div>
<h3>Methods</h3>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkRunner.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    &#34;&#34;&#34;Run the benchmark.&#34;&#34;&#34;
    # Set up signal handlers
    signal.signal(signal.SIGINT, self._handle_signal)
    signal.signal(signal.SIGTERM, self._handle_signal)

    # Register cleanup on exit
    atexit.register(self._cleanup_all_processes)

    print(&#34;=&#34; * 80)
    print(&#34;ENRGDAQ Benchmark&#34;)
    print(&#34;=&#34; * 80)
    print(&#34;Configuration:&#34;)
    print(f&#34;  - Clients:        {self.config.num_clients}&#34;)
    print(f&#34;  - Payload Size:   {self.config.payload_size} values/message&#34;)
    print(f&#34;  - Duration:       {self.config.duration_seconds} seconds&#34;)
    print(f&#34;  - ZMQ XSUB URL:   {self.config.zmq_xsub_url}&#34;)
    print(f&#34;  - ZMQ XPUB URL:   {self.config.zmq_xpub_url}&#34;)
    print(&#34;=&#34; * 80)
    print()

    # Clean up any existing output files from previous runs
    output_files_to_clean = [&#34;out/test.root&#34;]
    for output_file in output_files_to_clean:
        if os.path.exists(output_file):
            os.remove(output_file)
            print(f&#34;Removed existing output file: {output_file}&#34;)

    # Create shared array to track client ring buffer bytes (one c_longlong per client)
    self._client_shm_bytes = Array(&#34;q&#34;, self.config.num_clients)  # &#39;q&#39; = c_longlong

    # Start main supervisor process
    print(&#34;Starting main supervisor...&#34;)
    main_process = Process(
        target=run_main_supervisor,
        args=(
            self.config,
            self._stats_queue,
            self._stop_flag,
            self._client_shm_bytes,
        ),
    )
    main_process.start()
    self._processes.append(main_process)

    # Give main supervisor time to start (ZMQ needs to bind first)
    time.sleep(1)

    # Create ready events for each client
    ready_events = [Event() for _ in range(self.config.num_clients)]

    # Start client processes
    print(f&#34;Starting {self.config.num_clients} client(s)...&#34;)
    for i in range(self.config.num_clients):
        client_process = Process(
            target=run_client_supervisor,
            args=(
                i,
                self.config,
                self._stop_flag,
                ready_events[i],
                self._client_shm_bytes,
            ),
        )
        client_process.start()
        self._processes.append(client_process)

    # Wait for all clients to signal ready (with timeout)
    print(&#34;Waiting for clients to be ready...&#34;)
    all_ready = all(event.wait(timeout=30) for event in ready_events)
    if not all_ready:
        print(&#34;WARNING: Not all clients signaled ready within timeout&#34;)

    print()
    print(&#34;Benchmark running... (waiting for first data)&#34;)
    print(&#34;-&#34; * 80)

    # Timer starts when first data arrives, not now
    start_time: datetime | None = None
    end_time_seconds = self.config.duration_seconds

    try:
        while not self._stop_flag.value:
            # Check for stats in queue
            try:
                stats_dict = self._stats_queue.get(timeout=0.5)
                stats = self._dict_to_stats(stats_dict)

                # Start timer when first data arrives
                if start_time is None and stats.msg_in_count &gt; 0:
                    start_time = datetime.now()
                    print(&#34;First data received, starting timer...&#34;)

                self._stats_history.append(stats)
                self._print_stats(stats)
            except Exception:
                pass

            # Check duration (only if timer has started)
            if start_time is not None:
                elapsed = (datetime.now() - start_time).total_seconds()
                if elapsed &gt;= end_time_seconds:
                    print(f&#34;\nDuration of {end_time_seconds}s reached, stopping...&#34;)
                    break

    finally:
        self._stop_flag.value = True

        # Print summary
        self._print_summary()

        # Clean up all processes
        self._cleanup_all_processes()

        # Unregister atexit since we&#39;ve already cleaned up
        try:
            atexit.unregister(self._cleanup_all_processes)
        except Exception:
            pass</code></pre>
</details>
<div class="desc"><p>Run the benchmark.</p></div>
</dd>
</dl>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats"><code class="flex name class">
<span>class <span class="ident">BenchmarkStats</span></span>
<span>(</span><span>timestamp: datetime.datetime,<br>supervisor_id: str,<br>msg_in_out_mb: float,<br>msg_in_count: int,<br>msg_out_count: int,<br>msg_in_out_mb_per_s: float,<br>avg_queue_size: float,<br>active_job_count: int,<br>cpu_usage_percent: float,<br>rss_mb: float,<br>latency_p95_ms: float,<br>latency_p99_ms: float,<br>shm_bytes_written: int = 0,<br>shm_mb_per_s: float = 0.0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class BenchmarkStats:
    &#34;&#34;&#34;Statistics collected during benchmark run.&#34;&#34;&#34;

    timestamp: datetime
    supervisor_id: str
    msg_in_out_mb: float
    msg_in_count: int
    msg_out_count: int
    msg_in_out_mb_per_s: float
    avg_queue_size: float
    active_job_count: int
    cpu_usage_percent: float
    rss_mb: float
    latency_p95_ms: float
    latency_p99_ms: float
    shm_bytes_written: int = 0
    shm_mb_per_s: float = 0.0</code></pre>
</details>
<div class="desc"><p>Statistics collected during benchmark run.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.active_job_count"><code class="name">var <span class="ident">active_job_count</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.avg_queue_size"><code class="name">var <span class="ident">avg_queue_size</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.cpu_usage_percent"><code class="name">var <span class="ident">cpu_usage_percent</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p95_ms"><code class="name">var <span class="ident">latency_p95_ms</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p99_ms"><code class="name">var <span class="ident">latency_p99_ms</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_count"><code class="name">var <span class="ident">msg_in_count</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb"><code class="name">var <span class="ident">msg_in_out_mb</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb_per_s"><code class="name">var <span class="ident">msg_in_out_mb_per_s</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_out_count"><code class="name">var <span class="ident">msg_out_count</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.rss_mb"><code class="name">var <span class="ident">rss_mb</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.shm_bytes_written"><code class="name">var <span class="ident">shm_bytes_written</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.shm_mb_per_s"><code class="name">var <span class="ident">shm_mb_per_s</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.supervisor_id"><code class="name">var <span class="ident">supervisor_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.timestamp"><code class="name">var <span class="ident">timestamp</span> : datetime.datetime</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="enrgdaq.tools" href="index.html">enrgdaq.tools</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="enrgdaq.tools.benchmark_runner.cleanup_supervisor" href="#enrgdaq.tools.benchmark_runner.cleanup_supervisor">cleanup_supervisor</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.create_supervisor_config" href="#enrgdaq.tools.benchmark_runner.create_supervisor_config">create_supervisor_config</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.create_supervisor_info" href="#enrgdaq.tools.benchmark_runner.create_supervisor_info">create_supervisor_info</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.kill_process_tree" href="#enrgdaq.tools.benchmark_runner.kill_process_tree">kill_process_tree</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.parse_args" href="#enrgdaq.tools.benchmark_runner.parse_args">parse_args</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.run_client_supervisor" href="#enrgdaq.tools.benchmark_runner.run_client_supervisor">run_client_supervisor</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.run_main_supervisor" href="#enrgdaq.tools.benchmark_runner.run_main_supervisor">run_main_supervisor</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.run_supervisor_with_stats" href="#enrgdaq.tools.benchmark_runner.run_supervisor_with_stats">run_supervisor_with_stats</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a></code></h4>
<ul class="">
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.duration_seconds" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.duration_seconds">duration_seconds</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.num_clients" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.num_clients">num_clients</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_remote_stats_csv" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_remote_stats_csv">output_remote_stats_csv</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_stats_csv" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_stats_csv">output_stats_csv</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.payload_size" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.payload_size">payload_size</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.stats_interval_seconds" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.stats_interval_seconds">stats_interval_seconds</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_memory_store" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_memory_store">use_memory_store</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_shm" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_shm">use_shm</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.void_memory_data" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.void_memory_data">void_memory_data</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.zmq_xpub_url" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.zmq_xpub_url">zmq_xpub_url</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.zmq_xsub_url" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.zmq_xsub_url">zmq_xsub_url</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkRunner" href="#enrgdaq.tools.benchmark_runner.BenchmarkRunner">BenchmarkRunner</a></code></h4>
<ul class="">
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkRunner.run" href="#enrgdaq.tools.benchmark_runner.BenchmarkRunner.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats">BenchmarkStats</a></code></h4>
<ul class="two-column">
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.active_job_count" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.active_job_count">active_job_count</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.avg_queue_size" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.avg_queue_size">avg_queue_size</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.cpu_usage_percent" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.cpu_usage_percent">cpu_usage_percent</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p95_ms" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p95_ms">latency_p95_ms</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p99_ms" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p99_ms">latency_p99_ms</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_count" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_count">msg_in_count</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb">msg_in_out_mb</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb_per_s" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb_per_s">msg_in_out_mb_per_s</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_out_count" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_out_count">msg_out_count</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.rss_mb" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.rss_mb">rss_mb</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.shm_bytes_written" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.shm_bytes_written">shm_bytes_written</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.shm_mb_per_s" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.shm_mb_per_s">shm_mb_per_s</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.supervisor_id" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.supervisor_id">supervisor_id</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.timestamp" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.timestamp">timestamp</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
