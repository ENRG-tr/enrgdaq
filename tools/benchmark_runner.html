<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>enrgdaq.tools.benchmark_runner API documentation</title>
<meta name="description" content="ENRGDAQ Benchmark Script …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>enrgdaq.tools.benchmark_runner</code></h1>
</header>
<section id="section-intro">
<p>ENRGDAQ Benchmark Script</p>
<p>This script benchmarks the ENRGDAQ system by running a supervisor instance
with benchmark jobs that stress test message throughput, serialization, and storage.</p>
<p>The new architecture uses ZMQ pub/sub messaging through a single supervisor's
message broker. For distributed benchmarking, use the federation feature.</p>
<h2 id="usage">Usage</h2>
<p>python benchmark_runner.py [&ndash;clients N] [&ndash;payload-size N] [&ndash;duration SECONDS]</p>
<h2 id="example">Example</h2>
<p>python benchmark_runner.py &ndash;clients 5 &ndash;payload-size 10000 &ndash;duration 30</p>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.cleanup_supervisor"><code class="name flex">
<span>def <span class="ident">cleanup_supervisor</span></span>(<span>supervisor: <a title="enrgdaq.supervisor.Supervisor" href="../supervisor.html#enrgdaq.supervisor.Supervisor">Supervisor</a>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cleanup_supervisor(supervisor: Supervisor):
    &#34;&#34;&#34;Clean up supervisor and all its child processes.&#34;&#34;&#34;
    try:
        supervisor.stop()
        # Give a moment for clean shutdown
        time.sleep(0.1)
        # Force kill any remaining DAQ job processes
        for process in supervisor.daq_job_processes:
            if process.process and process.process.is_alive() and process.process.pid:
                kill_process_tree(process.process.pid)
    except Exception:
        pass</code></pre>
</details>
<div class="desc"><p>Clean up supervisor and all its child processes.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.create_supervisor_config"><code class="name flex">
<span>def <span class="ident">create_supervisor_config</span></span>(<span>supervisor_id: str) ‑> <a title="enrgdaq.models.SupervisorConfig" href="../models.html#enrgdaq.models.SupervisorConfig">SupervisorConfig</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_supervisor_config(supervisor_id: str) -&gt; SupervisorConfig:
    &#34;&#34;&#34;Create a SupervisorConfig instance.&#34;&#34;&#34;
    return SupervisorConfig(info=create_supervisor_info(supervisor_id))</code></pre>
</details>
<div class="desc"><p>Create a SupervisorConfig instance.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.create_supervisor_info"><code class="name flex">
<span>def <span class="ident">create_supervisor_info</span></span>(<span>supervisor_id: str) ‑> <a title="enrgdaq.models.SupervisorInfo" href="../models.html#enrgdaq.models.SupervisorInfo">SupervisorInfo</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_supervisor_info(supervisor_id: str) -&gt; SupervisorInfo:
    &#34;&#34;&#34;Create a SupervisorInfo instance.&#34;&#34;&#34;
    return SupervisorInfo(supervisor_id=supervisor_id)</code></pre>
</details>
<div class="desc"><p>Create a SupervisorInfo instance.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.kill_process_tree"><code class="name flex">
<span>def <span class="ident">kill_process_tree</span></span>(<span>pid: int, sig=15)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kill_process_tree(pid: int, sig=signal.SIGTERM):
    &#34;&#34;&#34;Kill a process and all its children using psutil.&#34;&#34;&#34;
    try:
        parent = psutil.Process(pid)
        children = parent.children(recursive=True)

        # Kill children first
        for child in children:
            try:
                child.send_signal(sig)
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass

        # Kill parent
        try:
            parent.send_signal(sig)
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            pass

        # Wait for processes to terminate
        gone, alive = psutil.wait_procs(children + [parent], timeout=1)

        # Force kill any remaining
        for p in alive:
            try:
                p.kill()
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass

    except psutil.NoSuchProcess:
        pass</code></pre>
</details>
<div class="desc"><p>Kill a process and all its children using psutil.</p></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.parse_args"><code class="name flex">
<span>def <span class="ident">parse_args</span></span>(<span>) ‑> <a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_args() -&gt; BenchmarkConfig:
    &#34;&#34;&#34;Parse command line arguments.&#34;&#34;&#34;
    parser = argparse.ArgumentParser(
        description=&#34;ENRGDAQ Benchmark Script&#34;,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=&#34;&#34;&#34;
Examples:
  python benchmark_runner.py                           # Run with defaults
  python benchmark_runner.py --clients 10              # Run with 10 benchmark jobs
  python benchmark_runner.py --payload-size 50000      # Larger payloads
  python benchmark_runner.py --duration 120            # Run for 2 minutes
        &#34;&#34;&#34;,
    )
    parser.add_argument(
        &#34;--clients&#34;,
        type=int,
        default=DEFAULT_NUM_CLIENTS,
        help=f&#34;Number of benchmark jobs (default: {DEFAULT_NUM_CLIENTS})&#34;,
    )
    parser.add_argument(
        &#34;--payload-size&#34;,
        type=int,
        default=DEFAULT_PAYLOAD_SIZE,
        help=f&#34;Number of values per message (default: {DEFAULT_PAYLOAD_SIZE})&#34;,
    )
    parser.add_argument(
        &#34;--duration&#34;,
        type=int,
        default=DEFAULT_DURATION_SECONDS,
        help=f&#34;Benchmark duration in seconds (default: {DEFAULT_DURATION_SECONDS})&#34;,
    )
    parser.add_argument(
        &#34;--stats-interval&#34;,
        type=float,
        default=DEFAULT_STATS_INTERVAL_SECONDS,
        help=f&#34;Stats collection interval in seconds (default: {DEFAULT_STATS_INTERVAL_SECONDS})&#34;,
    )
    parser.add_argument(
        &#34;--no-void-data&#34;,
        action=&#34;store_true&#34;,
        help=&#34;Don&#39;t void memory store data (uses more memory)&#34;,
    )
    parser.add_argument(
        &#34;--use-shm&#34;,
        action=&#34;store_true&#34;,
        default=True,
        help=&#34;Use SHM for zero-copy (default: True)&#34;,
    )
    parser.add_argument(
        &#34;--no-shm&#34;,
        action=&#34;store_false&#34;,
        dest=&#34;use_shm&#34;,
        help=&#34;Disable SHM&#34;,
    )
    parser.add_argument(
        &#34;--use-memory-store&#34;,
        action=&#34;store_true&#34;,
        help=&#34;Use Memory store instead of ROOT store&#34;,
    )

    args = parser.parse_args()

    return BenchmarkConfig(
        num_clients=args.clients,
        payload_size=args.payload_size,
        duration_seconds=args.duration,
        stats_interval_seconds=args.stats_interval,
        void_memory_data=not args.no_void_data,
        use_memory_store=args.use_memory_store,
        use_shm=args.use_shm,
    )</code></pre>
</details>
<div class="desc"><p>Parse command line arguments.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig"><code class="flex name class">
<span>class <span class="ident">BenchmarkConfig</span></span>
<span>(</span><span>num_clients: int = 5,<br>payload_size: int = 1000,<br>duration_seconds: int = 60,<br>stats_interval_seconds: float = 1,<br>output_stats_csv: str = 'benchmark_stats.csv',<br>void_memory_data: bool = True,<br>use_memory_store: bool = False,<br>use_shm: bool = True)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class BenchmarkConfig:
    &#34;&#34;&#34;Configuration for benchmark run.&#34;&#34;&#34;

    num_clients: int = DEFAULT_NUM_CLIENTS
    payload_size: int = DEFAULT_PAYLOAD_SIZE
    duration_seconds: int = DEFAULT_DURATION_SECONDS
    stats_interval_seconds: float = DEFAULT_STATS_INTERVAL_SECONDS
    output_stats_csv: str = &#34;benchmark_stats.csv&#34;
    void_memory_data: bool = True
    use_memory_store: bool = False
    use_shm: bool = True</code></pre>
</details>
<div class="desc"><p>Configuration for benchmark run.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.duration_seconds"><code class="name">var <span class="ident">duration_seconds</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.num_clients"><code class="name">var <span class="ident">num_clients</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_stats_csv"><code class="name">var <span class="ident">output_stats_csv</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.payload_size"><code class="name">var <span class="ident">payload_size</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.stats_interval_seconds"><code class="name">var <span class="ident">stats_interval_seconds</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_memory_store"><code class="name">var <span class="ident">use_memory_store</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_shm"><code class="name">var <span class="ident">use_shm</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkConfig.void_memory_data"><code class="name">var <span class="ident">void_memory_data</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkRunner"><code class="flex name class">
<span>class <span class="ident">BenchmarkRunner</span></span>
<span>(</span><span>config: <a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a>)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BenchmarkRunner:
    &#34;&#34;&#34;Runs the ENRGDAQ benchmark and collects statistics.&#34;&#34;&#34;

    def __init__(self, config: BenchmarkConfig):
        self.config = config
        self._stop_flag = Value(&#34;b&#34;, False)
        self._stats_history: list[BenchmarkStats] = []
        self._main_pid = os.getpid()
        self._supervisor: Supervisor | None = None

    def _print_stats(self, stats: BenchmarkStats):
        &#34;&#34;&#34;Print statistics to console.&#34;&#34;&#34;
        print(
            f&#34;[{stats.timestamp.strftime(&#39;%H:%M:%S&#39;)}] &#34;
            f&#34;Data: {stats.data_mb_per_s:7.2f} MB/s | &#34;
            f&#34;CPU: {stats.cpu_usage_percent:5.1f}% | &#34;
            f&#34;p95 Latency: {stats.latency_p95_ms:5.2f}ms | &#34;
            f&#34;Active Jobs: {stats.active_job_count:3d}&#34;
        )

    def _handle_signal(self, signum, frame):
        &#34;&#34;&#34;Handle termination signals.&#34;&#34;&#34;
        print(&#34;\nReceived termination signal, stopping...&#34;)
        self._stop_flag.value = True

    def _cleanup(self):
        &#34;&#34;&#34;Clean up the supervisor.&#34;&#34;&#34;
        print(&#34;\nTerminating...&#34;)
        self._stop_flag.value = True
        if self._supervisor:
            cleanup_supervisor(self._supervisor)

    def _create_supervisor(self) -&gt; Supervisor:
        &#34;&#34;&#34;Create and configure the benchmark supervisor.&#34;&#34;&#34;
        config = self.config

        # Create temporary config directory for the supervisor
        temp_config_dir = tempfile.mkdtemp(prefix=&#34;enrgdaq_benchmark_&#34;)

        supervisor_id = &#34;benchmark_supervisor&#34;
        supervisor_info = create_supervisor_info(supervisor_id)
        supervisor_config = create_supervisor_config(supervisor_id)
        supervisor_config.ring_buffer_size_mb = 1024
        supervisor_config.ring_buffer_slot_size_kb = 10 * 1024

        # Create DAQ job processes using the proper factory function
        daq_job_processes = []

        # Benchmark jobs that generate data
        for i in range(config.num_clients):
            daq_job_processes.append(
                _create_daq_job_process(
                    DAQJobBenchmark,
                    DAQJobBenchmarkConfig(
                        daq_job_type=&#34;DAQJobBenchmark&#34;,
                        payload_size=config.payload_size,
                        use_shm=config.use_shm,
                        store_config=DAQJobStoreConfig(
                            memory=DAQJobStoreConfigMemory(),
                            target_local_supervisor=True,  # Enable SHM for local transfer
                        )
                        if config.use_memory_store
                        else DAQJobStoreConfig(
                            root=DAQJobStoreConfigROOT(
                                file_path=f&#34;benchmark_{i}.root&#34;,
                                add_date=False,
                                tree_name=&#34;benchmark_tree&#34;,
                            ),
                            target_local_supervisor=True,  # Enable SHM for local transfer
                        ),
                    ),
                    supervisor_info,
                )
            )

        # Main store - either Memory (fast, for testing) or ROOT (slow, for production)
        if config.use_memory_store:
            daq_job_processes.append(
                _create_daq_job_process(
                    DAQJobStoreMemory,
                    DAQJobStoreMemoryConfig(
                        daq_job_type=&#34;DAQJobStoreMemory&#34;,
                        void_data=config.void_memory_data,
                    ),
                    supervisor_info,
                )
            )
        else:
            daq_job_processes.append(
                _create_daq_job_process(
                    DAQJobStoreROOT,
                    DAQJobStoreROOTConfig(
                        daq_job_type=&#34;DAQJobStoreROOT&#34;, verbosity=LogVerbosity.DEBUG
                    ),
                    supervisor_info,
                )
            )

        # CSV store for stats output
        daq_job_processes.append(
            _create_daq_job_process(
                DAQJobStoreCSV,
                DAQJobStoreCSVConfig(daq_job_type=&#34;DAQJobStoreCSV&#34;),
                supervisor_info,
            )
        )

        # Stats handler
        daq_job_processes.append(
            _create_daq_job_process(
                DAQJobHandleStats,
                DAQJobHandleStatsConfig(
                    daq_job_type=&#34;DAQJobHandleStats&#34;,
                    store_config=DAQJobStoreConfig(
                        csv=DAQJobStoreConfigCSV(
                            file_path=config.output_stats_csv,
                            overwrite=True,
                        ),
                    ),
                ),
                supervisor_info,
            )
        )

        return Supervisor(
            config=supervisor_config,
            daq_job_processes=daq_job_processes,
            daq_job_config_path=temp_config_dir,
        )

    def _collect_stats(self) -&gt; BenchmarkStats | None:
        &#34;&#34;&#34;Collect current statistics from the supervisor.&#34;&#34;&#34;
        if self._supervisor is None or self._supervisor.config is None:
            return None

        supervisor = self._supervisor
        supervisor_id = supervisor.config.info.supervisor_id

        # Calculate active job count
        active_job_count = len(
            [
                x
                for x in supervisor.daq_job_processes
                if x.process and x.process.is_alive()
            ]
        )

        # Get byte stats from daq_job_remote_stats (like old benchmark did)
        # Format: dict[supervisor_id, SupervisorRemoteStats]
        remote_stats = supervisor.daq_job_remote_stats

        # Get our supervisor&#39;s stats
        our_stats = remote_stats.get(supervisor_id)
        if our_stats:
            msg_in_out_bytes = our_stats.message_in_bytes + our_stats.message_out_bytes
            msg_in_out_mb = msg_in_out_bytes / 10**6
            msg_in_count = our_stats.message_in_count
            msg_out_count = our_stats.message_out_count
        else:
            msg_in_out_mb = 0.0
            msg_in_count = 0
            msg_out_count = 0

        # Get latency stats from daq_job_stats
        # Format: dict[supervisor_id, dict[daq_job_type, DAQJobStats]]
        stats_nested = supervisor.daq_job_stats
        all_stats: list = []
        for sup_id, daq_job_stats_dict in stats_nested.items():
            if isinstance(daq_job_stats_dict, dict):
                for daq_job_type, job_stats in daq_job_stats_dict.items():
                    all_stats.append(job_stats)

        # Calculate CPU and Memory usage from stats
        cpu_usage = (
            sum(s.resource_stats.cpu_percent for s in all_stats) if all_stats else 0.0
        )
        rss_mb_total = (
            sum(s.resource_stats.rss_mb for s in all_stats) if all_stats else 0.0
        )

        # Calculate Latency (max of p95/p99 across jobs to be conservative)
        p95_latencies = [
            s.latency_stats.p95_ms for s in all_stats if s.latency_stats.count &gt; 0
        ]
        p99_latencies = [
            s.latency_stats.p99_ms for s in all_stats if s.latency_stats.count &gt; 0
        ]

        latency_p95 = max(p95_latencies) if p95_latencies else 0.0
        latency_p99 = max(p99_latencies) if p99_latencies else 0.0

        return BenchmarkStats(
            timestamp=datetime.now(),
            supervisor_id=supervisor_id,
            msg_in_out_mb=msg_in_out_mb,
            msg_in_count=msg_in_count,
            msg_out_count=msg_out_count,
            msg_in_out_mb_per_s=0.0,  # Will be calculated from deltas
            active_job_count=active_job_count,
            cpu_usage_percent=cpu_usage,
            rss_mb=rss_mb_total,
            latency_p95_ms=latency_p95,
            latency_p99_ms=latency_p99,
            data_mb_per_s=0.0,  # Will be calculated from deltas
        )

    def run(self):
        &#34;&#34;&#34;Run the benchmark.&#34;&#34;&#34;
        # Set up signal handlers
        signal.signal(signal.SIGINT, self._handle_signal)
        signal.signal(signal.SIGTERM, self._handle_signal)

        # Register cleanup on exit
        atexit.register(self._cleanup)

        print(&#34;=&#34; * 80)
        print(&#34;ENRGDAQ Benchmark&#34;)
        print(&#34;=&#34; * 80)
        print(&#34;Configuration:&#34;)
        print(f&#34;  - Benchmark Jobs: {self.config.num_clients}&#34;)
        print(f&#34;  - Payload Size:   {self.config.payload_size} values/message&#34;)
        print(f&#34;  - Duration:       {self.config.duration_seconds} seconds&#34;)
        print(f&#34;  - Use SHM:        {self.config.use_shm}&#34;)
        print(
            f&#34;  - Store Type:     {&#39;Memory&#39; if self.config.use_memory_store else &#39;ROOT&#39;}&#34;
        )
        print(&#34;=&#34; * 80)
        print()

        # Clean up any existing output files from previous runs
        output_files_to_clean = [&#34;out/benchmark_*.root&#34;]
        for pattern in output_files_to_clean:
            import glob

            for output_file in glob.glob(pattern):
                os.remove(output_file)
                print(f&#34;Removed existing output file: {output_file}&#34;)

        # Create and initialize supervisor
        print(&#34;Creating supervisor...&#34;)
        self._supervisor = self._create_supervisor()

        print(&#34;Initializing supervisor...&#34;)
        self._supervisor.init()

        # Start supervisor in a separate thread
        supervisor_thread = Thread(target=self._supervisor.run, daemon=True)
        supervisor_thread.start()

        print()
        print(&#34;Benchmark running... (waiting for first data)&#34;)
        print(&#34;-&#34; * 80)

        # Timer starts when first data arrives, not now
        start_time: datetime | None = None
        end_time_seconds = self.config.duration_seconds
        last_stats: BenchmarkStats | None = None
        last_iteration = datetime.now()

        try:
            while not self._stop_flag.value:
                current_stats = self._collect_stats()

                if current_stats is None:
                    time.sleep(self.config.stats_interval_seconds)
                    continue

                # Start timer when first data arrives
                if start_time is None and current_stats.msg_in_count &gt; 0:
                    start_time = datetime.now()
                    print(&#34;First data received, starting timer...&#34;)

                # Calculate deltas for MB/s
                now = datetime.now()
                elapsed = (now - last_iteration).total_seconds()
                if last_stats and elapsed &gt; 0:
                    mb_diff = current_stats.msg_in_out_mb - last_stats.msg_in_out_mb
                    current_stats.msg_in_out_mb_per_s = mb_diff / elapsed

                    # Calculate data throughput
                    msg_diff = current_stats.msg_in_count - last_stats.msg_in_count
                    msg_size_bytes = self.config.payload_size * 16  # 2 float64 columns
                    current_stats.data_mb_per_s = (
                        (msg_diff * msg_size_bytes) / elapsed / 10**6
                    )

                self._stats_history.append(current_stats)
                self._print_stats(current_stats)

                last_stats = current_stats
                last_iteration = now

                # Check duration (only if timer has started)
                if start_time is not None:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    if elapsed &gt;= end_time_seconds:
                        print(f&#34;\nDuration of {end_time_seconds}s reached, stopping...&#34;)
                        break

                time.sleep(self.config.stats_interval_seconds)

        finally:
            self._stop_flag.value = True

            # Print summary
            self._print_summary()

            # Clean up
            self._cleanup()

            # Unregister atexit since we&#39;ve already cleaned up
            try:
                atexit.unregister(self._cleanup)
            except Exception:
                pass

    def _print_summary(self):
        &#34;&#34;&#34;Print benchmark summary statistics.&#34;&#34;&#34;
        # Filter to stats with actual data, skipping the first 3 seconds of warmup
        data_stats = [s for s in self._stats_history if s.msg_in_count &gt; 0]
        if len(data_stats) &gt; 3:
            data_stats = data_stats[3:]

        if not data_stats:
            print(&#34;\nNo statistics collected.&#34;)
            return

        print()
        print(&#34;=&#34; * 80)
        print(&#34;Benchmark Summary&#34;)
        print(&#34;=&#34; * 80)

        # Calculate duration from first data to last data
        total_duration = (
            data_stats[-1].timestamp - data_stats[0].timestamp
        ).total_seconds()

        if total_duration &lt;= 0:
            total_duration = 1.0

        avg_throughput = fmean([s.msg_in_out_mb_per_s for s in data_stats])
        avg_data_throughput = fmean([s.data_mb_per_s for s in data_stats])
        max_data_throughput = max([s.data_mb_per_s for s in data_stats])
        total_mb = data_stats[-1].msg_in_out_mb
        total_msgs = data_stats[-1].msg_in_count

        print(f&#34;Duration:              {total_duration:.1f} seconds&#34;)
        print(f&#34;Avg Data Throughput:   {avg_data_throughput:.2f} MB/s&#34;)
        print(f&#34;Peak Data Throughput:  {max_data_throughput:.2f} MB/s&#34;)
        print(f&#34;Total Data:            {total_mb:.2f} MB&#34;)
        print(f&#34;ZMQ Throughput:        {avg_throughput:.2f} MB/s&#34;)
        print(f&#34;Total Messages:        {total_msgs:,}&#34;)
        print(f&#34;Messages/Second:       {total_msgs / total_duration:,.0f}&#34;)
        print(
            f&#34;Avg CPU Usage:         {fmean([s.cpu_usage_percent for s in data_stats]):.1f}%&#34;
        )
        print(
            f&#34;Avg p95 Latency:       {fmean([s.latency_p95_ms for s in data_stats]):.2f} ms&#34;
        )
        print(
            f&#34;Peak p99 Latency:      {max([s.latency_p99_ms for s in data_stats]):.2f} ms&#34;
        )
        print(&#34;=&#34; * 80)</code></pre>
</details>
<div class="desc"><p>Runs the ENRGDAQ benchmark and collects statistics.</p></div>
<h3>Methods</h3>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkRunner.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    &#34;&#34;&#34;Run the benchmark.&#34;&#34;&#34;
    # Set up signal handlers
    signal.signal(signal.SIGINT, self._handle_signal)
    signal.signal(signal.SIGTERM, self._handle_signal)

    # Register cleanup on exit
    atexit.register(self._cleanup)

    print(&#34;=&#34; * 80)
    print(&#34;ENRGDAQ Benchmark&#34;)
    print(&#34;=&#34; * 80)
    print(&#34;Configuration:&#34;)
    print(f&#34;  - Benchmark Jobs: {self.config.num_clients}&#34;)
    print(f&#34;  - Payload Size:   {self.config.payload_size} values/message&#34;)
    print(f&#34;  - Duration:       {self.config.duration_seconds} seconds&#34;)
    print(f&#34;  - Use SHM:        {self.config.use_shm}&#34;)
    print(
        f&#34;  - Store Type:     {&#39;Memory&#39; if self.config.use_memory_store else &#39;ROOT&#39;}&#34;
    )
    print(&#34;=&#34; * 80)
    print()

    # Clean up any existing output files from previous runs
    output_files_to_clean = [&#34;out/benchmark_*.root&#34;]
    for pattern in output_files_to_clean:
        import glob

        for output_file in glob.glob(pattern):
            os.remove(output_file)
            print(f&#34;Removed existing output file: {output_file}&#34;)

    # Create and initialize supervisor
    print(&#34;Creating supervisor...&#34;)
    self._supervisor = self._create_supervisor()

    print(&#34;Initializing supervisor...&#34;)
    self._supervisor.init()

    # Start supervisor in a separate thread
    supervisor_thread = Thread(target=self._supervisor.run, daemon=True)
    supervisor_thread.start()

    print()
    print(&#34;Benchmark running... (waiting for first data)&#34;)
    print(&#34;-&#34; * 80)

    # Timer starts when first data arrives, not now
    start_time: datetime | None = None
    end_time_seconds = self.config.duration_seconds
    last_stats: BenchmarkStats | None = None
    last_iteration = datetime.now()

    try:
        while not self._stop_flag.value:
            current_stats = self._collect_stats()

            if current_stats is None:
                time.sleep(self.config.stats_interval_seconds)
                continue

            # Start timer when first data arrives
            if start_time is None and current_stats.msg_in_count &gt; 0:
                start_time = datetime.now()
                print(&#34;First data received, starting timer...&#34;)

            # Calculate deltas for MB/s
            now = datetime.now()
            elapsed = (now - last_iteration).total_seconds()
            if last_stats and elapsed &gt; 0:
                mb_diff = current_stats.msg_in_out_mb - last_stats.msg_in_out_mb
                current_stats.msg_in_out_mb_per_s = mb_diff / elapsed

                # Calculate data throughput
                msg_diff = current_stats.msg_in_count - last_stats.msg_in_count
                msg_size_bytes = self.config.payload_size * 16  # 2 float64 columns
                current_stats.data_mb_per_s = (
                    (msg_diff * msg_size_bytes) / elapsed / 10**6
                )

            self._stats_history.append(current_stats)
            self._print_stats(current_stats)

            last_stats = current_stats
            last_iteration = now

            # Check duration (only if timer has started)
            if start_time is not None:
                elapsed = (datetime.now() - start_time).total_seconds()
                if elapsed &gt;= end_time_seconds:
                    print(f&#34;\nDuration of {end_time_seconds}s reached, stopping...&#34;)
                    break

            time.sleep(self.config.stats_interval_seconds)

    finally:
        self._stop_flag.value = True

        # Print summary
        self._print_summary()

        # Clean up
        self._cleanup()

        # Unregister atexit since we&#39;ve already cleaned up
        try:
            atexit.unregister(self._cleanup)
        except Exception:
            pass</code></pre>
</details>
<div class="desc"><p>Run the benchmark.</p></div>
</dd>
</dl>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats"><code class="flex name class">
<span>class <span class="ident">BenchmarkStats</span></span>
<span>(</span><span>timestamp: datetime.datetime,<br>supervisor_id: str,<br>msg_in_out_mb: float,<br>msg_in_count: int,<br>msg_out_count: int,<br>msg_in_out_mb_per_s: float,<br>active_job_count: int,<br>cpu_usage_percent: float,<br>rss_mb: float,<br>latency_p95_ms: float,<br>latency_p99_ms: float,<br>data_mb_per_s: float = 0.0)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class BenchmarkStats:
    &#34;&#34;&#34;Statistics collected during benchmark run.&#34;&#34;&#34;

    timestamp: datetime
    supervisor_id: str
    msg_in_out_mb: float
    msg_in_count: int
    msg_out_count: int
    msg_in_out_mb_per_s: float
    active_job_count: int
    cpu_usage_percent: float
    rss_mb: float
    latency_p95_ms: float
    latency_p99_ms: float
    data_mb_per_s: float = 0.0</code></pre>
</details>
<div class="desc"><p>Statistics collected during benchmark run.</p></div>
<h3>Instance variables</h3>
<dl>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.active_job_count"><code class="name">var <span class="ident">active_job_count</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.cpu_usage_percent"><code class="name">var <span class="ident">cpu_usage_percent</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.data_mb_per_s"><code class="name">var <span class="ident">data_mb_per_s</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p95_ms"><code class="name">var <span class="ident">latency_p95_ms</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p99_ms"><code class="name">var <span class="ident">latency_p99_ms</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_count"><code class="name">var <span class="ident">msg_in_count</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb"><code class="name">var <span class="ident">msg_in_out_mb</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb_per_s"><code class="name">var <span class="ident">msg_in_out_mb_per_s</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_out_count"><code class="name">var <span class="ident">msg_out_count</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.rss_mb"><code class="name">var <span class="ident">rss_mb</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.supervisor_id"><code class="name">var <span class="ident">supervisor_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="enrgdaq.tools.benchmark_runner.BenchmarkStats.timestamp"><code class="name">var <span class="ident">timestamp</span> : datetime.datetime</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="enrgdaq.tools" href="index.html">enrgdaq.tools</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="enrgdaq.tools.benchmark_runner.cleanup_supervisor" href="#enrgdaq.tools.benchmark_runner.cleanup_supervisor">cleanup_supervisor</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.create_supervisor_config" href="#enrgdaq.tools.benchmark_runner.create_supervisor_config">create_supervisor_config</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.create_supervisor_info" href="#enrgdaq.tools.benchmark_runner.create_supervisor_info">create_supervisor_info</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.kill_process_tree" href="#enrgdaq.tools.benchmark_runner.kill_process_tree">kill_process_tree</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.parse_args" href="#enrgdaq.tools.benchmark_runner.parse_args">parse_args</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig">BenchmarkConfig</a></code></h4>
<ul class="">
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.duration_seconds" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.duration_seconds">duration_seconds</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.num_clients" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.num_clients">num_clients</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_stats_csv" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.output_stats_csv">output_stats_csv</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.payload_size" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.payload_size">payload_size</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.stats_interval_seconds" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.stats_interval_seconds">stats_interval_seconds</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_memory_store" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_memory_store">use_memory_store</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_shm" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.use_shm">use_shm</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkConfig.void_memory_data" href="#enrgdaq.tools.benchmark_runner.BenchmarkConfig.void_memory_data">void_memory_data</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkRunner" href="#enrgdaq.tools.benchmark_runner.BenchmarkRunner">BenchmarkRunner</a></code></h4>
<ul class="">
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkRunner.run" href="#enrgdaq.tools.benchmark_runner.BenchmarkRunner.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats">BenchmarkStats</a></code></h4>
<ul class="two-column">
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.active_job_count" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.active_job_count">active_job_count</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.cpu_usage_percent" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.cpu_usage_percent">cpu_usage_percent</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.data_mb_per_s" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.data_mb_per_s">data_mb_per_s</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p95_ms" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p95_ms">latency_p95_ms</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p99_ms" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.latency_p99_ms">latency_p99_ms</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_count" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_count">msg_in_count</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb">msg_in_out_mb</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb_per_s" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_in_out_mb_per_s">msg_in_out_mb_per_s</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_out_count" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.msg_out_count">msg_out_count</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.rss_mb" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.rss_mb">rss_mb</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.supervisor_id" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.supervisor_id">supervisor_id</a></code></li>
<li><code><a title="enrgdaq.tools.benchmark_runner.BenchmarkStats.timestamp" href="#enrgdaq.tools.benchmark_runner.BenchmarkStats.timestamp">timestamp</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
